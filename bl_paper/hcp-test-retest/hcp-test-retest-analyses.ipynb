{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,glob\n",
    "from matplotlib import colors as mcolors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### subjects\n",
    "def collectSubjectData(topPath,dataPath,groups,subjects,colors):\n",
    "\n",
    "    # set up variables\n",
    "    data_columns = ['subjectID','classID','colors']\n",
    "    data =  pd.DataFrame([],columns=data_columns)\n",
    "\n",
    "    # populate structure\n",
    "    data['subjectID'] = [ f for g in groups for f in subjects[g] ]\n",
    "    data['classID'] = [ g for g in groups for f in range(len(subjects[g]))]\n",
    "    data['colors'] = [ colors[c] for c in colors for f in subjects[c]]\n",
    "\n",
    "    # output data structure for records and any further analyses\n",
    "    if not os.path.exists(dataPath):\n",
    "        os.mkdir(dataPath)\n",
    "\n",
    "    data.to_csv(dataPath+'subjects.csv',index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "### color dictionary\n",
    "def createColorDictionary(data,measure,colorPalette):\n",
    "\n",
    "    keys = data[measure].unique()\n",
    "    values = sns.color_palette(colorPalette,len(keys))\n",
    "    values = values.as_hex()\n",
    "\n",
    "    colors_dict = dict(zip(keys,values))\n",
    "\n",
    "    return colors_dict\n",
    "\n",
    "### load parcellation stats data \n",
    "### load data \n",
    "# def collectData(datatype,datatype_tags,tags,filename,subjects_data,colors,outPath):\n",
    "\n",
    "#     import requests\n",
    "#     import pandas as pd\n",
    "\n",
    "#     # grab path and data objects\n",
    "#     objects = requests.get('https://brainlife.io/api/warehouse/secondary/list/%s'%os.environ['PROJECT_ID']).json()\n",
    "    \n",
    "#     # subjects and paths\n",
    "#     subjects = []\n",
    "#     paths = []\n",
    "    \n",
    "#     # set up output\n",
    "#     data = pd.DataFrame()\n",
    "\n",
    "#     # loop through objects\n",
    "#     for obj in objects:\n",
    "#         if obj['datatype']['name'] == datatype:\n",
    "#             if datatype_tags in obj['output']['datatype_tags']:\n",
    "# #                 if tags in obj['output']['tags']:\n",
    "#                 if set(obj['output']['tags']).issubset(tags):\n",
    "#                     subjects = np.append(subjects,obj['output']['meta']['subject'])\n",
    "#                     paths = np.append(paths,\"input/\"+obj[\"path\"]+\"/\"+filename)\n",
    "    \n",
    "#     # sort paths by subject order\n",
    "#     paths = [x for _,x in sorted(zip(subjects,paths))]\n",
    "\n",
    "#     for i in paths:\n",
    "#         tmpdata = pd.read_csv(i)\n",
    "#         if tmpdata.subjectID.dtypes != 'object':\n",
    "#             tmpdata['subjectID'] = [ str(int(np.float(f))) for f in tmpdata.subjectID ]\n",
    "# #         if 'classID' in tmpdata.keys():\n",
    "# #             tmpdata = pd.merge(tmpdata,subjects_data,on=['subjectID','classID'])\n",
    "# #         else:\n",
    "# #             tmpdata = pd.merge(tmpdata,subjects_data,on='subjectID')\n",
    "#         data = data.append(tmpdata,ignore_index=True)\n",
    "            \n",
    "#     # replace empty spaces with nans\n",
    "#     data = data.replace(r'^\\s+$', np.nan, regex=True)\n",
    "\n",
    "#     # output data structure for records and any further analyses\n",
    "#     # subjects.csv\n",
    "#     data.to_csv(outPath,index=False)\n",
    "\n",
    "#     return data\n",
    "def collectData(datatype,datatype_tags,tags,filename,subjects_data,colors,outPath):\n",
    "\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "\n",
    "    # grab path and data objects\n",
    "    objects = requests.get('https://brainlife.io/api/warehouse/secondary/list/%s'%os.environ['PROJECT_ID']).json()\n",
    "\n",
    "    # subjects and paths\n",
    "    subjects = []\n",
    "    paths = []\n",
    "\n",
    "    # set up output\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    # loop through objects\n",
    "    for obj in objects:\n",
    "        if obj['datatype']['name'] == datatype:\n",
    "            if datatype_tags in obj['output']['datatype_tags']:\n",
    "    #                 if tags in obj['output']['tags']:\n",
    "                if set(tags).issubset(obj['output']['tags']):\n",
    "\n",
    "                    subjects = np.append(subjects,obj['output']['meta']['subject'])\n",
    "                    paths = np.append(paths,\"input/\"+obj[\"path\"]+\"/\"+filename)\n",
    "                elif '!' in str(tags):\n",
    "                    tag = [ f for f in tags if '!' in str(f) ]\n",
    "                    tag_drop = [ f for f in tags if f not in tag ]\n",
    "                    if not set([ f.replace('!','') for f in tag]).issubset(obj['output']['tags']):\n",
    "                        if set(tag_drop).issubset(obj['output']['tags']):\n",
    "                            subjects = np.append(subjects,obj['output']['meta']['subject'])\n",
    "                            paths = np.append(paths,\"input/\"+obj[\"path\"]+\"/\"+filename)\n",
    "\n",
    "    paths = [y for _,y in sorted(zip(subjects,paths))]\n",
    "    subjects = [x for x,_ in sorted(zip(subjects,paths))]\n",
    "\n",
    "    for i in paths:\n",
    "        if '.json.gz' in filename:\n",
    "            tmpdata = pd.read_json(i,orient='index').reset_index(drop=True)\n",
    "            tmpdata['subjectID'] = [ str(subjects[f]) for f in range(len(subjects)) if i == paths[f]]\n",
    "#             tmpdata = pd.merge(tmpdata,subjects_data)\n",
    "        else:\n",
    "            tmpdata = pd.read_csv(i)\n",
    "        if tmpdata.subjectID.dtypes != 'object':\n",
    "            tmpdata['subjectID'] = [ str(int(np.float(f))) for f in tmpdata.subjectID ]\n",
    "    #         if 'classID' in tmpdata.keys():\n",
    "    #             tmpdata = pd.merge(tmpdata,subjects_data,on=['subjectID','classID'])\n",
    "    #         else:\n",
    "    #             tmpdata = pd.merge(tmpdata,subjects_data,on='subjectID')\n",
    "        data = data.append(tmpdata,ignore_index=True)\n",
    "\n",
    "    # replace empty spaces with nans\n",
    "    data = data.replace(r'^\\s+$', np.nan, regex=True)\n",
    "\n",
    "    # drop duplicates\n",
    "    data = data.drop_duplicates('subjectID')\n",
    "\n",
    "    # output data structure for records and any further analyses\n",
    "    # subjects.csv\n",
    "    data.to_csv(outPath,index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def collectNetworkData(datatype,datatype_tags,tags,corr_filename,labels_filename,subjects_data,colors,outPath):\n",
    "\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "\n",
    "    # grab path and data objects\n",
    "    objects = requests.get('https://brainlife.io/api/warehouse/secondary/list/%s'%os.environ['PROJECT_ID']).json()\n",
    "\n",
    "    # subjects and paths\n",
    "    subjects = []\n",
    "    csv_paths = []\n",
    "    label_paths = []\n",
    "\n",
    "    # set up output\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    # loop through objects\n",
    "    for obj in objects:\n",
    "        if obj['datatype']['name'] == datatype:\n",
    "            if datatype_tags in obj['output']['datatype_tags']:\n",
    "                if tags in obj['output']['tags']:\n",
    "                    subjects = np.append(subjects,obj['output']['meta']['subject'])\n",
    "                    csv_paths = np.append(csv_paths,\"input/\"+obj[\"path\"]+\"/\"+corr_filename)\n",
    "                    label_paths = np.append(label_paths,\"input/\"+obj[\"path\"]+\"/\"+labels_filename)\n",
    "\n",
    "    # sort paths by subject order\n",
    "    subjects = [x for _,x in sorted(zip(subjects,subjects))]\n",
    "    csv_paths = [x for _,x in sorted(zip(subjects,csv_paths))]\n",
    "    label_paths = [x for _,x in sorted(zip(subjects,label_paths))]\n",
    "\n",
    "    for i in range(len(csv_paths)):\n",
    "        tmplabel = pd.read_json(label_paths[i])\n",
    "        label_names = [ f for f in tmplabel['name'] if f not in ['self-loop'] ]\n",
    "        tmpdata = pd.read_csv(csv_paths[i],names=label_names)\n",
    "        tmpdata.index = label_names\n",
    "        tmpdata['subjectID'] = [ subjects[i] for f in range(len(tmpdata)) ]\n",
    "        if tmpdata.subjectID.dtypes != 'object':\n",
    "            tmpdata['subjectID'] = [ str(int(np.float(f))) for f in tmpdata.subjectID ]\n",
    "        if 'classID' in tmpdata.keys():\n",
    "            tmpdata = pd.merge(tmpdata,subjects_data,on=['subjectID','classID'],right_index=True)\n",
    "        else:\n",
    "            tmpdata = pd.merge(tmpdata,subjects_data,on='subjectID',right_index=True)\n",
    "        data = data.append(tmpdata)\n",
    "\n",
    "    # replace empty spaces with nans\n",
    "    data = data.replace(r'^\\s+$', np.nan, regex=True)\n",
    "\n",
    "    # output data structure for records and any further analyses\n",
    "    # subjects.csv\n",
    "    data.to_csv(outPath)\n",
    "\n",
    "    return data\n",
    "\n",
    "### cut nodes\n",
    "def cutNodes(data,num_nodes,dataPath,foldername,savename):\n",
    "\n",
    "    # identify inner n nodes based on num_nodes input\n",
    "    total_nodes = len(data['nodeID'].unique())\n",
    "    cut_nodes = int((total_nodes - num_nodes) / 2)\n",
    "\n",
    "    # remove cut_nodes from dataframe\n",
    "    data = data[data['nodeID'].between((cut_nodes)+1,(num_nodes+cut_nodes))]\n",
    "\n",
    "    # replace empty spaces with nans\n",
    "    data = data.replace(r'^\\s+$', np.nan, regex=True)\n",
    "\n",
    "    # output data structure for records and any further analyses\n",
    "    if not os.path.exists(dataPath):\n",
    "        os.mkdir(dataPath)\n",
    "\n",
    "    data.to_csv(dataPath+'/'+foldername+'-'+savename+'.csv',index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "def computeMeanData(dataPath,data,outname):\n",
    "\n",
    "    # make mean data frame\n",
    "    data_mean =  data.groupby(['subjectID','classID','structureID']).mean().reset_index()\n",
    "    data_mean['nodeID'] = [ 1 for f in range(len(data_mean['nodeID'])) ]\n",
    "\n",
    "    # output data structure for records and any further analyses\n",
    "    if not os.path.exists(dataPath):\n",
    "        os.mkdir(dataPath)\n",
    "\n",
    "    data_mean.to_csv(dataPath+outname+'.csv',index=False)\n",
    "\n",
    "    return data_mean\n",
    "\n",
    "### rank order effect size calculator\n",
    "def computeRankOrderEffectSize(groups,subjects,tissue,measures,stat,measures_to_average,data_dir):\n",
    "\n",
    "    comparison_array = list(combinations(groups,2)) # 2 x 2 array; 2 different comparisons, with two pairs per comparison. comparison_array[0] = (\"run_1\",\"run_2\")\n",
    "    es = {}\n",
    "    roes = {}\n",
    "\n",
    "    # compute effect size\n",
    "    for compar in comparison_array:\n",
    "        es[compar[0]+\"_\"+compar[1]] = pd.DataFrame([])\n",
    "        tmp = pd.DataFrame([])\n",
    "        tmp['structureID'] = stat['structureID'].unique()\n",
    "        for m in measures:\n",
    "            diff = stat[['structureID',m]][stat['classID'].str.contains(compar[0])].groupby('structureID').mean() - stat[['structureID',m]][stat['classID'].str.contains(compar[1])].groupby('structureID').mean()\n",
    "            pooled_var = (np.sqrt((stat[['structureID',m]][stat['classID'].str.contains(compar[0])].groupby('structureID').std() ** 2 + stat[['structureID',m]][stat['classID'].str.contains(compar[1])].groupby('structureID').std() ** 2) / 2))\n",
    "            effectSize = diff / pooled_var\n",
    "            tmp[m+\"_effect_size\"] = list(effectSize[m])\n",
    "        tmp.to_csv(data_dir+tissue+\"_effect_sizes_\"+compar[0]+\"_\"+compar[1]+\".csv\",index=False)\n",
    "        es[compar[0]+\"_\"+compar[1]] = pd.concat([es[compar[0]+\"_\"+compar[1]],tmp],ignore_index=True)\n",
    "\n",
    "    # rank order structures\n",
    "    for ma in measures_to_average:\n",
    "        if ma == ['ad','fa','md','rd','ga','ak','mk','rk']:\n",
    "            model = 'tensor'\n",
    "        elif ma == ['ndi','isovf','odi']:\n",
    "            model = 'noddi'\n",
    "        else:\n",
    "            model = ma\n",
    "\n",
    "        tmpdata = pd.DataFrame([])\n",
    "        tmpdata['structureID'] = stat['structureID'].unique()\n",
    "        for compar in comparison_array:\n",
    "            if model == 'tensor':\n",
    "                tmpdata[compar[0]+\"_\"+compar[1]+\"_\"+model+\"_average_effect_size\"] = es[compar[0]+\"_\"+compar[1]][['ad_effect_size','fa_effect_size','md_effect_size','rd_effect_size']].abs().mean(axis=1).tolist()\n",
    "            elif model == 'noddi':\n",
    "                tmpdata[compar[0]+\"_\"+compar[1]+\"_\"+model+\"_average_effect_size\"] = es[compar[0]+\"_\"+compar[1]][['ndi_effect_size','isovf_effect_size','odi_effect_size']].abs().mean(axis=1).tolist()\n",
    "            else:\n",
    "                tmpdata[compar[0]+\"_\"+compar[1]+\"_\"+model+\"_average_effect_size\"] = es[compar[0]+\"_\"+compar[1]][[ma+'_effect_size']].abs().mean(axis=1).tolist()\n",
    "\n",
    "        tmpdata[model+\"_average_effect_size\"] =  tmpdata.mean(axis=1).tolist()\n",
    "        tmpdata.to_csv(data_dir+model+\"_average_\"+tissue+\"_effect_sizes.csv\",index=False)\n",
    "        roes[model] = tmpdata.sort_values(by=model+\"_average_effect_size\")['structureID'].tolist()\n",
    "\n",
    "    return roes\n",
    "\n",
    "def combineCorticalSubcortical(dataPath,corticalData,subcorticalData):\n",
    "\n",
    "    # remove unnecessary columns\n",
    "    corticalData = corticalData.drop(columns=['snr','thickness'])\n",
    "    subcorticalData = subcorticalData.drop(columns=['parcID','number_of_voxels'])\n",
    "\n",
    "    # merge data frames\n",
    "    data = pd.concat([corticalData,subcorticalData],sort=False)\n",
    "\n",
    "    # output data structure for records and any further analyses\n",
    "    if not os.path.exists(dataPath):\n",
    "        os.mkdir(dataPath)\n",
    "\n",
    "    data.to_csv(dataPath+'graymatter_nodes.csv',index=False)\n",
    "\n",
    "    # identify gray matter names\n",
    "    graymatter_names = list(data['structureID'].unique())\n",
    "\n",
    "    # output track names\n",
    "    if not os.path.exists(dataPath):\n",
    "        os.mkdir(dataPath)\n",
    "\n",
    "    with open((dataPath+'graymatter_list.json'),'w') as gm_listf:\n",
    "        json.dump(graymatter_names,gm_listf)\n",
    "\n",
    "    return [graymatter_names,data]\n",
    "\n",
    "def computeDistance(x,y,metric):\n",
    "\n",
    "    from sklearn.metrics.pairwise import euclidean_distances\n",
    "    from scipy.stats import wasserstein_distance\n",
    "\n",
    "    if metric == 'euclidean':\n",
    "        dist = euclidean_distances([x,y])[0][1]\n",
    "    else:\n",
    "        dist = wasserstein_distance(x,y)\n",
    "        \n",
    "    return dist\n",
    "\n",
    "def computeReferences(x,groupby_measures,index_measure,diff_measures):\n",
    "    \n",
    "    references_mean = x.groupby(groupby_measures).mean().reset_index(index_measure)\n",
    "    references_sd = x.groupby(groupby_measures).std().reset_index(index_measure)\n",
    "    references_sd[diff_measures] = references_sd[diff_measures] * 2\n",
    "    \n",
    "    return references_mean, references_sd\n",
    "\n",
    "def createDistanceDataframe(data,structures,groupby_measure,measures,dist_metric):\n",
    "    \n",
    "    dist = []\n",
    "    subj = []\n",
    "    meas = []\n",
    "    struc = []\n",
    "\n",
    "    for i in structures:\n",
    "        print(i)\n",
    "        subj_data = data.loc[data['structureID'] == i]\n",
    "        references_data = computeReferences(subj_data,groupby_measure,groupby_measure,measures)\n",
    "        for m in measures:\n",
    "            for s in subj_data.subjectID.unique():\n",
    "                x = list(subj_data.loc[subj_data['subjectID'] == s][m].values.tolist())\n",
    "                y = list(references_data[0][m].values.tolist())\n",
    "                dist = np.append(dist,computeDistance(x,y,dist_metric))\n",
    "                subj = np.append(subj,s)\n",
    "                meas = np.append(meas,m)\n",
    "                struc = np.append(struc,i)\n",
    "\n",
    "    dist_dataframe = pd.DataFrame()\n",
    "    dist_dataframe['subjectID'] = subj\n",
    "    dist_dataframe['structureID'] = struc\n",
    "    dist_dataframe['measures'] = meas\n",
    "    dist_dataframe['distance'] = dist\n",
    "    \n",
    "    return dist_dataframe\n",
    "\n",
    "def buildReferenceData(data,outliers,profile):\n",
    "    \n",
    "    reference_data = pd.DataFrame()\n",
    "    \n",
    "    for s in outliers.structureID.unique():\n",
    "        for m in outliers.measures.unique():\n",
    "            if profile:\n",
    "                tmpdata = data.loc[data['structureID'] == s].loc[~data['subjectID'].isin(outliers.loc[outliers['structureID'] == s].loc[outliers['measures'] == m].subjectID.unique())][['structureID','subjectID','nodeID',m]].reset_index(drop=True)\n",
    "            else:\n",
    "                tmpdata = data.loc[data['structureID'] == s].loc[~data['subjectID'].isin(outliers.loc[outliers['structureID'] == s].loc[outliers['measures'] == m].subjectID.unique())][['structureID','subjectID',m]].reset_index(drop=True)\n",
    "            reference_data = pd.concat([reference_data,tmpdata])\n",
    "    if not profile:\n",
    "        reference_data = reference_data.groupby(['structureID','subjectID']).mean().reset_index()\n",
    "    \n",
    "    return reference_data\n",
    "\n",
    "def computeOutliers(distances,threshold):\n",
    "    \n",
    "    outliers = pd.DataFrame()\n",
    "    \n",
    "    for i in distances.structureID.unique():\n",
    "        for m in distances.measures.unique():\n",
    "            tmpdata = distances.loc[distances['structureID'] == i].loc[distances['measures'] == m]\n",
    "            outliers = pd.concat([outliers,tmpdata[tmpdata['distance'] > np.percentile(tmpdata['distance'],threshold)]])\n",
    "            \n",
    "    return outliers\n",
    "\n",
    "def outlierDetection(data,structures,groupby_measure,measures,threshold,dist_metric,build_outliers):\n",
    "    \n",
    "    import numpy as np, pandas as pd\n",
    "\n",
    "    outliers_subjects = []\n",
    "    outliers_structures = []\n",
    "    outliers_measures = []\n",
    "    outliers_metrics = []\n",
    "\n",
    "    distances = createDistanceDataframe(data,structures,groupby_measure,measures,dist_metric)\n",
    "    outliers_dataframe = computeOutliers(distances,threshold)\n",
    "    \n",
    "    if build_outliers:\n",
    "        if 'nodeID' in data.columns:\n",
    "            reference_dataframe = buildReferenceData(data,outliers_dataframe,True)\n",
    "        else:\n",
    "            reference_dataframe = buildReferenceData(data,outliers_dataframe,False)\n",
    "    else:\n",
    "        reference_dataframe = []\n",
    "        \n",
    "    return distances, outliers_dataframe, reference_dataframe\n",
    "\n",
    "def profileFlipCheck(data,subjects,structures,test_measure,flip_measures,dist_metric,threshold,outPath):\n",
    "    \n",
    "    flipped_subjects = []\n",
    "    flipped_structures = []\n",
    "    distance = []\n",
    "    flipped_distance = []\n",
    "    \n",
    "    for i in structures:\n",
    "        print(i)\n",
    "        struc_data = data.loc[data['structureID'] == i]\n",
    "        references_data = computeReferences(struc_data,'nodeID','nodeID',flip_measures)\n",
    "        differences = []\n",
    "        dist = []\n",
    "        dist_flipped = []\n",
    "\n",
    "        for s in subjects:\n",
    "            subj_data = struc_data.loc[data['subjectID'] == s]\n",
    "            x = list(subj_data[test_measure].values.tolist())\n",
    "            y = list(references_data[0][test_measure].values.tolist())\n",
    "            dist = np.append(dist,computeDistance(x,y,dist_metric))\n",
    "            dist_flipped = np.append(dist_flipped,computeDistance(list(np.flip(x)),y,dist_metric))\n",
    "            differences =  np.append(differences,(dist[-1]-dist_flipped[-1]))\n",
    "        \n",
    "        percentile_threshold = np.percentile(differences,threshold)\n",
    "#         print(percentile_threshold)\n",
    "        for m in range(len(differences)):\n",
    "            if differences[m] > 0 and differences[m] > percentile_threshold:\n",
    "#             if differences[m] > percentile_threshold:\n",
    "#                 print(subjects[m])\n",
    "                flipped_subjects = np.append(flipped_subjects,subjects[m])\n",
    "                flipped_structures = np.append(flipped_structures,i)\n",
    "                distance = np.append(distance,dist[m])\n",
    "                flipped_distance = np.append(flipped_distance,dist_flipped[m])\n",
    "    \n",
    "    output_summary = pd.DataFrame()\n",
    "    output_summary['flipped_subjects'] = flipped_subjects\n",
    "    output_summary['flipped_structures'] = flipped_structures\n",
    "    output_summary['distance'] = distance\n",
    "    output_summary['flipped_distance'] = flipped_distance\n",
    "    \n",
    "    if outPath:\n",
    "        output_summary.to_csv(outPath+'_flipped_profiles.csv',index=False)\n",
    "    \n",
    "    return output_summary\n",
    "\n",
    "### scatter plot related scripts\n",
    "# groups data by input measure and computes mean for each value in that column. x_stat is a pd dataframe, with each row being a single value, and each column being a different ID value or measure\n",
    "def averageWithinColumn(x_stat,y_stat,x_measure,y_measure,measure):\n",
    "\n",
    "    X = x_stat.groupby(measure).mean()[x_measure].tolist()\n",
    "    Y = y_stat.groupby(measure).mean()[y_measure].tolist()\n",
    "\n",
    "    return X,Y\n",
    "\n",
    "# groups data by input measure and creates an array by appending data into x and y arrays. x_stat and y_stat are pd dataframes, with each row being a single value, and each column being a different ID value or measure\n",
    "# designed for test retest. x_stat and y_stat should have the same number of rows. but more importantly, should correspond to the same source (i.e. subject)\n",
    "# can be same pd.dataframe, but indexing of specific subject groups\n",
    "def appendWithinColumn(x_stat,y_stat,x_measure,y_measure,measure):\n",
    "\n",
    "    X,Y = [np.array([]),np.array([])]\n",
    "    for i in range(len(x_stat[measure].unique())):\n",
    "        x = x_stat[x_stat[measure] == x_stat[measure].unique()[i]][x_measure]\n",
    "        y = y_stat[y_stat[measure] == y_stat[measure].unique()[i]][y_measure]\n",
    "\n",
    "        if np.isnan(x).any() or np.isnan(y).any():\n",
    "            print(\"skipping %s due to nan\" %x_stat[measure].unique()[i])\n",
    "        else:\n",
    "            # checks to make sure the same data\n",
    "            if len(x) == len(y):\n",
    "                X = np.append(X,x)\n",
    "                Y = np.append(Y,y)\n",
    "\n",
    "    return X,Y\n",
    "\n",
    "# unravels networks. x_stat and y_stat should be S x M, where S is the number of subjects and M is the adjacency matrix for that subject\n",
    "def ravelNetwork(x_stat,y_stat):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    X = np.ravel(x_stat).tolist()\n",
    "    Y = np.ravel(y_stat).tolist()\n",
    "\n",
    "    return X,Y\n",
    "\n",
    "# unravels nonnetwork data. x_stat and y_stat should be pd dataframes. x_measure and y_measure are the measure to unrvavel. \n",
    "# designed for test retest. x_stat and y_stat should have the same number of rows. but more importantly, should correspond to the same source (i.e. subject)\n",
    "# can be same pd.dataframe, but indexing of specific subject groups\n",
    "def ravelNonNetwork(x_stat,y_stat,x_measure,y_measure):\n",
    "\n",
    "    X = x_stat[x_measure].to_list()\n",
    "    Y = y_stat[y_measure].to_list()\n",
    "\n",
    "    return X,Y\n",
    "\n",
    "# wrapper function to call either of the above scripts based on user input\n",
    "def setupData(x_data,y_data,x_measure,y_measure,ravelAverageAppend,isnetwork,measure):\n",
    "\n",
    "    x_stat = x_data\n",
    "    y_stat = y_data\n",
    "\n",
    "    if ravelAverageAppend == 'average':\n",
    "        X,Y = averageWithinColumn(x_stat,y_stat,x_measure,y_measure,measure)\n",
    "    elif ravelAverageAppend == 'append':\n",
    "        X,Y = appendWithinColumn(x_stat,y_stat,x_measure,y_measure,measure)\n",
    "    elif ravelAverageAppend == 'ravel':\n",
    "        if isnetwork == True:\n",
    "            X,Y = ravelNetwork(x_stat,y_stat)\n",
    "        else:\n",
    "            X,Y = ravelNonNetwork(x_stat,y_stat,x_measure,y_measure)\n",
    "\n",
    "    return x_stat,y_stat,X,Y\n",
    "\n",
    "# function to shuffle data and colors\n",
    "def shuffleDataAlg(X,Y,hues):\n",
    "\n",
    "    from sklearn.utils import shuffle\n",
    "\n",
    "    X,Y,hues = shuffle(X,Y,hues)\n",
    "\n",
    "    return X,Y,hues\n",
    "\n",
    "# simple display or figure save function\n",
    "def saveOrShowImg(dir_out,x_measure,y_measure,img_name):\n",
    "    import os,sys \n",
    "    import matplotlib.pyplot as plt\n",
    "    import warnings\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        # this will suppress all warnings in this block\n",
    "        warnings.simplefilter(\"ignore\")\n",
    " \n",
    "        # save or show plot\n",
    "        if dir_out:\n",
    "            if not os.path.exists(dir_out):\n",
    "                os.mkdir(dir_out)\n",
    "\n",
    "            if x_measure == y_measure:\n",
    "                img_name_eps = img_name+'_'+x_measure+'.eps'\n",
    "                img_name_png = img_name+'_'+x_measure+'.png'\n",
    "                img_name_svg = img_name+'_'+x_measure+'.svg'\n",
    "            else:\n",
    "                img_name_eps = img_name+'_'+x_measure+'_vs_'+y_measure+'.eps'\n",
    "                img_name_png = img_name+'_'+x_measure+'_vs_'+y_measure+'.png'\n",
    "                img_name_svg = img_name+'_'+x_measure+'_vs_'+y_measure+'.svg'\n",
    "\n",
    "            plt.savefig(os.path.join(dir_out, img_name_eps),transparent=True)\n",
    "            plt.savefig(os.path.join(dir_out, img_name_png))     \n",
    "    #         plt.savefig(os.path.join(dir_out, img_name_svg))\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close()\n",
    "    \n",
    "# uses seaborn's relplot function to plot data for each unique value in a column of a pandas dataframe (ex. subjects, structureID). useful for supplementary figures or sanity checking or preliminary results\n",
    "# column measure is the measure within which each unique value will have its own plot. hue_measure is the column to use for coloring the data. column_wrap is how many panels you want per row\n",
    "# trendline, depending on user input, can either be the linear regression between x_data[x_measure] and y_data[y_measure] or the line of equality\n",
    "# dir_out and img_name are the directory where the figures should be saved and the name for the image. will save .eps and .png\n",
    "# if want to view plot instead of save, set dir_out=\"\"\n",
    "def relplotScatter(x_data,y_data,x_measure,y_measure,column_measure,hue_measure,column_wrap,trendline,dir_out,img_name):\n",
    "\n",
    "    import os,sys\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    # grab data: CANNOT BE AVERAGE\n",
    "    [x_stat,y_stat,X,Y] = setupData(x_data,y_data,x_measure,y_measure,'ravel',False,hue_measure)\n",
    "\n",
    "    p = sns.relplot(x=X,y=Y,col=x_stat[column_measure],hue=x_stat[hue_measure],kind=\"scatter\",s=100,col_wrap=column_wrap)\n",
    "\n",
    "    # setting counter. looping through axes to add important info and regression lines\n",
    "    i = 0\n",
    "    for ax in p.axes.flat:\n",
    "        x_lim,y_lim = [ax.get_xlim(),ax.get_ylim()]\n",
    "\n",
    "        if trendline == 'equality':\n",
    "            ax.plot(x_lim,y_lim,ls=\"--\",c='k')\n",
    "        elif trendline == 'linreg':\n",
    "            m,b = np.polyfit(p.data[p.data[column_measure] == x_stat[column_measure].unique()[i]]['x'],p.data[p.data[column_measure] == y_stat[column_measure].unique()[i]]['y'],1)\n",
    "            ax.plot(ax.get_xticks(),m*ax.get_xticks() + b)\n",
    "            plt.text(0.1,0.7,'y = %s x + %s' %(str(np.round(m,4)),str(np.round(b,4))),fontsize=12,verticalalignment=\"top\",horizontalalignment=\"left\",transform=ax.transAxes)\n",
    "\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "        ax.set_xlabel(x_measure)\n",
    "        ax.set_ylabel(y_measure)\n",
    "\n",
    "        # compute correlation for each subject and add to plots\n",
    "        corr = np.corrcoef(p.data[p.data[column_measure] == x_stat[column_measure].unique()[i]]['x'],p.data[p.data[column_measure] == y_stat[column_measure].unique()[i]]['y'])[1][0]\n",
    "        plt.text(0.1,0.9,'r = %s' %str(np.round(corr,4)),fontsize=12,verticalalignment=\"top\",horizontalalignment=\"left\",transform=ax.transAxes)\n",
    "\n",
    "        # compute rmse for each subject and add to plots\n",
    "        rmse = np.sqrt(mean_squared_error(p.data[p.data[column_measure] == x_stat[column_measure].unique()[i]]['x'],p.data[p.data[column_measure] == y_stat[column_measure].unique()[i]]['y']))\n",
    "        plt.text(0.1,0.8,'rmse = %s' %str(np.round(rmse,4)),fontsize=12,verticalalignment=\"top\",horizontalalignment=\"left\",transform=ax.transAxes)\n",
    "\n",
    "        # update counter\n",
    "        i = i+1\n",
    "\n",
    "    # save image or show image\n",
    "    saveOrShowImg(dir_out,x_measure,y_measure,img_name)\n",
    "\n",
    "# uses seaborn's scatter function to plot data from x_data[x_measure] and y_data[y_measure]. useful for publication worthy figure\n",
    "# column measure is the measure within which data will be summarized. hue_measure is the column to use for coloring the data. \n",
    "# ravelAverageAppend is a string value of either 'append' to use the append function, 'ravel' to use the ravel function, or 'average' to use the average function\n",
    "# trendline, depending on user input, can either be the linear regression between x_data[x_measure] and y_data[y_measure] or the line of equality\n",
    "# dir_out and img_name are the directory where the figures should be saved and the name for the image. will save .eps and .png\n",
    "# if want to view plot instead of save, set dir_out=\"\"\n",
    "def singleplotScatter(colors_dict,x_data,y_data,x_measure,y_measure,logX,column_measure,hue_measure,ravelAverageAppend,trendline,shuffleData,dir_out,img_name):\n",
    "\n",
    "    import os,sys\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    # grab data\n",
    "    [x_stat,y_stat,X,Y] = setupData(x_data,y_data,x_measure,y_measure,ravelAverageAppend,False,column_measure)\n",
    "    colors = sns.color_palette('colorblind',len(x_stat[hue_measure]))\n",
    "\n",
    "    if ravelAverageAppend == 'average':\n",
    "        if isinstance(x_stat[hue_measure].unique()[0],str):\n",
    "            hues = x_stat[hue_measure].unique().tolist()\n",
    "        else:\n",
    "            hues = x_stat.groupby(column_measure).mean()[hue_measure].tolist()\n",
    "    else:\n",
    "        hues = list(x_stat[hue_measure])\n",
    "\n",
    "    if shuffleData == True:\n",
    "        X,Y,hues = shuffleDataAlg(X,Y,hues)\n",
    "\n",
    "    if logX == True:\n",
    "        X = np.log10(X)\n",
    "\n",
    "    if colors_dict:\n",
    "        p = sns.scatterplot(x=X,y=Y,hue=hues,s=100,palette=colors_dict,legend=False)\n",
    "    else:\n",
    "        p = sns.scatterplot(x=X,y=Y,hue=hues,s=100)\t\t\t\t\t\n",
    "\n",
    "    # set x and ylimits, plot line of equality, and legend\n",
    "    if x_measure == y_measure:\n",
    "        p.axes.axis('square')\n",
    "        y_ticks = p.axes.get_yticks()\n",
    "        p.axes.set_xticks(y_ticks)\n",
    "        p.axes.set_yticks(p.axes.get_xticks())\n",
    "        p.axes.set_ylim(p.axes.get_xlim())\n",
    "        p.axes.set_xlim(p.axes.get_xlim())\n",
    "\n",
    "    x_lim,y_lim = [p.axes.get_xlim(),p.axes.get_ylim()]\n",
    "\n",
    "    # trendline: either equality or linear regression\n",
    "    if trendline == 'equality':\n",
    "        p.plot(x_lim,y_lim,ls=\"--\",c='k')\n",
    "    elif trendline == 'linreg':\n",
    "        m,b = np.polyfit(X,Y,1)\n",
    "        p.plot(p.get_xticks(),m*p.get_xticks() + b,c='k')\n",
    "        plt.text(0.1,0.7,'y = %s x + %s' %(str(np.round(m,4)),str(np.round(b,4))),fontsize=16,verticalalignment=\"top\",horizontalalignment=\"left\",transform=p.axes.transAxes)\n",
    "        ax = plt.gca()\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "    elif trendline == 'groupreg':\n",
    "        for g in range(len(groups)):\n",
    "            if stat_name == 'volume':\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(np.log10(stat[['structureID',stat_name]][stat['subjectID'].str.contains('%s_' %str(g+1))].groupby('structureID',as_index=False).mean()[stat_name]),stat[['structureID',dm]][stat['subjectID'].str.contains('%s_' %str(g+1))].groupby('structureID',as_index=False).mean()[dm])\n",
    "                ax = sns.regplot(x=np.log10(stat[['structureID',stat_name]][stat['subjectID'].str.contains('%s_' %str(g+1))].groupby('structureID',as_index=False).mean()[stat_name]),y=stat[['structureID',dm]][stat['subjectID'].str.contains('%s_' %str(g+1))].groupby('structureID',as_index=False).mean()[dm],color=colors[groups[g]],scatter=True,line_kws={'label':\"y={0:.5f}x+{1:.4f}\".format(slope,intercept)})\n",
    "\n",
    "            else:\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(stat[['structureID',stat_name]][stat['subjectID'].str.contains('%s_' %str(g+1))].groupby('structureID',as_index=False).mean()[stat_name],stat[['structureID',dm]][stat['subjectID'].str.contains('%s_' %str(g+1))].groupby('structureID',as_index=False).mean()[dm])\n",
    "                ax = sns.regplot(x=stat[['structureID',stat_name]][stat['subjectID'].str.contains('%s_' %str(g+1))].groupby('structureID',as_index=False).mean()[stat_name],y=stat[['structureID',dm]][stat['subjectID'].str.contains('%s_' %str(g+1))].groupby('structureID',as_index=False).mean()[dm],color=colors[groups[g]],scatter=True,line_kws={'label':\"y={0:.5f}x+{1:.4f}\".format(slope,intercept)})\n",
    "\n",
    "            ax.legend()\n",
    "\n",
    "\n",
    "    # compute correlation for each subject and add to plots\n",
    "    corr = np.corrcoef(X,Y)[1][0]\n",
    "    plt.text(0.1,0.9,'r = %s' %str(np.round(corr,4)),fontsize=16,verticalalignment=\"top\",horizontalalignment=\"left\",transform=p.axes.transAxes)\n",
    "\n",
    "    # compute rmse for each subject and add to plots\n",
    "    rmse = np.sqrt(mean_squared_error(X,Y))\n",
    "    plt.text(0.1,0.8,'rmse = %s' %str(np.round(rmse,4)),fontsize=16,verticalalignment=\"top\",horizontalalignment=\"left\",transform=p.axes.transAxes)\n",
    "\n",
    "    # set title and x and y labels\n",
    "    plt.title('%s vs %s' %(x_measure,y_measure),fontsize=20)\n",
    "    plt.xlabel(x_measure,fontsize=18)\n",
    "    plt.ylabel(y_measure,fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "\n",
    "    # remove top and right spines from plot\n",
    "    p.axes.spines[\"top\"].set_visible(False)\n",
    "    p.axes.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # save image or show image\n",
    "    saveOrShowImg(dir_out,x_measure,y_measure,img_name)\n",
    "\n",
    "# uses seaborn's scatter function to plot data from x_data[x_measure] and y_data[y_measure] for network correlations. useful for publication worthy figure\n",
    "# column measure is the measure within which data will be summarized.\n",
    "# ravelAverageAppend is a string value of either 'append' to use the append function, 'ravel' to use the ravel function, or 'average' to use the average function\n",
    "# trendline, depending on user input, can either be the linear regression between x_data[x_measure] and y_data[y_measure] or the line of equality\n",
    "# dir_out and img_name are the directory where the figures should be saved and the name for the image. will save .eps and .png\n",
    "# if want to view plot instead of save, set dir_out=\"\"\n",
    "def networkScatter(colors_dict,hues,groups,subjects,x_data,y_data,network_measure,shuffleData,trendline,dir_out,img_name):\n",
    "\n",
    "    import os,sys\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    # generate new figure for each\n",
    "    p = plt.figure()\n",
    "\n",
    "    # grab data\n",
    "#     [x_stat,y_stat,X,Y] = setupData(x_data,y_data,\"\",\"\",\"ravel\",True,\"\")\n",
    "\n",
    "    # additional network setup\n",
    "    # hues = sns.color_palette(colormap,len(X))\n",
    "    # hues = hues.as_hex()\n",
    "    # keys = [ i for i in range(len(X)) ]\n",
    "    # colors_dict = dict(zip(hues,hues))\n",
    "\n",
    "#     if shuffleData == True:\n",
    "#         X,Y,hues = shuffleDataAlg(X,Y,hues)\n",
    "\n",
    "    # if colors_dict:\n",
    "        # p = sns.scatterplot(x=X,y=Y,hue=hues,s=100,palette=colors_dict,legend=False)\n",
    "    # else:\n",
    "    \n",
    "    p = sns.scatterplot(x=x_data,y=y_data,s=100,palette=colors_dict,legend=False)\n",
    "\n",
    "    # set x and ylimits, plot line of equality, and legend\n",
    "    p.axes.axis('square')\n",
    "    y_ticks = p.axes.get_yticks()\n",
    "    p.axes.set_xticks(y_ticks)\n",
    "    p.axes.set_yticks(p.axes.get_xticks())\n",
    "    p.axes.set_ylim(p.axes.get_xlim())\n",
    "    p.axes.set_xlim(p.axes.get_xlim())\n",
    "\n",
    "    x_lim,y_lim = [p.axes.get_xlim(),p.axes.get_ylim()]\n",
    "\n",
    "    # trendline: either equality or linear regression\n",
    "    if trendline == 'equality':\n",
    "        p.plot(x_lim,y_lim,ls=\"--\",c='k')\n",
    "    elif trendline == 'linreg':\n",
    "        m,b = np.polyfit(x_data,y_data,1)\n",
    "        p.plot(p.get_xticks(),m*p.get_xticks() + b,c='k')\n",
    "        plt.text(0.1,0.7,'y = %s x + %s' %(str(np.round(m,4)),str(np.round(b,4))),fontsize=16,verticalalignment=\"top\",horizontalalignment=\"left\",transform=p.axes.transAxes)\n",
    "\n",
    "    # compute correlation for each subject and add to plots\n",
    "    corr = np.corrcoef(x_data,y_data)[1][0]\n",
    "    plt.text(0.1,0.9,'r = %s' %str(np.round(corr,4)),fontsize=16,verticalalignment=\"top\",horizontalalignment=\"left\",transform=p.axes.transAxes)\n",
    "\n",
    "    # compute rmse for each subject and add to plots\n",
    "    rmse = np.sqrt(mean_squared_error(x_data,y_data))\n",
    "    plt.text(0.1,0.8,'rmse = %s' %str(np.round(rmse,4)),fontsize=16,verticalalignment=\"top\",horizontalalignment=\"left\",transform=p.axes.transAxes)\n",
    "\n",
    "    # set title and x and y labels\n",
    "    plt.title('%s %s vs %s' %(network_measure,groups[0],groups[1]),fontsize=20)\n",
    "    plt.xlabel(groups[0],fontsize=18)\n",
    "    plt.ylabel(groups[1],fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "\n",
    "    # remove top and right spines from plot\n",
    "    p.axes.spines[\"top\"].set_visible(False)\n",
    "    p.axes.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # save image or show image\n",
    "    saveOrShowImg(dir_out,network_measure+'_'+groups[0],network_measure+'_'+groups[1],img_name)\n",
    "\n",
    "# uses matplotlib.pyplot's hist2d function to plot data from x_data[x_measure] and y_data[y_measure]. useful for supplementary figure or debugging or publication worthy figure\n",
    "# column measure is the measure within which data will be summarized. hue_measure is the column to use for coloring the data. \n",
    "# ravelAverageAppend is a string value of either 'append' to use the append function, 'ravel' to use the ravel function, or 'average' to use the average function\n",
    "# trendline, depending on user input, can either be the linear regression between x_data[x_measure] and y_data[y_measure] or the line of equality\n",
    "# dir_out and img_name are the directory where the figures should be saved and the name for the image. will save .eps and .png\n",
    "# if want to view plot instead of save, set dir_out=\"\"\n",
    "def plot2dHist(x_data,y_data,x_measure,y_measure,column_measure,hue_measure,ravelAverageAppend,trendline,shuffleData,dir_out,img_name):\n",
    "\n",
    "    import os,sys\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    # grab data\n",
    "    [x_stat,y_stat,X,Y] = setupData(x_data,y_data,x_measure,y_measure,ravelAverageAppend,False,column_measure)\n",
    "\n",
    "    if ravelAverageAppend == 'average':\n",
    "        if isinstance(x_stat[hue_measure].unique()[0],str):\n",
    "            hues = x_stat[hue_measure].unique().tolist()\n",
    "        else:\n",
    "            hues = x_stat.groupby(column_measure).mean()[hue_measure].tolist()\n",
    "    else:\n",
    "        hues = list(x_stat[hue_measure])\n",
    "\n",
    "    if shuffleData == True:\n",
    "        X,Y,hues = shuffleDataAlg(X,Y,hues)\n",
    "\n",
    "\n",
    "    # generate new figure for each\n",
    "    p = plt.figure()\n",
    "\n",
    "    plt.hist2d(x=X,y=Y,cmin=1,density=False,bins=(len(X)/10),cmap='magma',vmax=(len(X)/10))\n",
    "    plt.colorbar()\n",
    "\n",
    "    # set title and x and y labels\n",
    "\n",
    "    plt.title('%s vs %s' %(x_measure,y_measure),fontsize=20)\n",
    "    plt.xlabel(x_measure,fontsize=18)\n",
    "    plt.ylabel(y_measure,fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "\n",
    "    # # remove top and right spines from plot\n",
    "    # p.axes.spines[\"top\"].set_visible(False)\n",
    "    # p.axes.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # save image or show image\n",
    "    saveOrShowImg(dir_out,x_measure,y_measure,img_name)\n",
    "\n",
    "### tract profile data\n",
    "# uses matplotlib.pyplot's plot and fill_between functions to plot tract profile data from stat. useful for publication worthy figure\n",
    "# requires stat to be formatted in way of AFQ_Brwoser and Yeatman et al 2018 () 'nodes.csv' files\n",
    "# groups is a list array of names of groups found in 'classID' of stat to plot\n",
    "# colors is a dictionary with the classID from groups set as the key and a color name as the value. will use these colors in profiles\n",
    "# tracks is a list array that will be looped through to make plots. if only one track is wanted, set structures=['structure_name'], with 'structure_name' being the name of the track in the 'structureID' field of stat\n",
    "# stat is the pandas dataframe with all of the profile data. each row is a node for a track for a subject\n",
    "# diffusion_measures is a list array of the column measures found within stat. was developed with diffusion MRI metrics in mind, but can be any measure\n",
    "# summary_method is a string of either 'mean' to plot the average profile data, 'max' to plot max, 'min' to plot min, and 'median' to plot median\n",
    "# error_method is a string of either 'std' for the error bars to be set to the standard deviation or 'sem' for standard error of mean\n",
    "# dir_out and imgName are the directory where the figures should be saved and the name for the image. will save .pdf and .png\n",
    "# if want to view plot instead of save, set dir_out=\"\"\n",
    "def plotProfiles(structures,stat,diffusion_measures,summary_method,error_method,dir_out,img_name):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os,sys\n",
    "    import seaborn as sns\n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # loop through all structures\n",
    "    for t in structures:\n",
    "        print(t)\n",
    "        # loop through all measures\n",
    "        for dm in diffusion_measures:\n",
    "            print(dm)\n",
    "\n",
    "            imgname=img_name+\"_\"+t+\"_\"+dm\n",
    "\n",
    "            # generate figures\n",
    "            fig = plt.figure(figsize=(15,15))\n",
    "#             fig = plt.figure()\n",
    "            fig.patch.set_visible(False)\n",
    "            p = plt.subplot()\n",
    "\n",
    "            # set title and catch array for legend handle\n",
    "            plt.title(\"%s Profiles %s: %s\" %(summary_method,t,dm),fontsize=20)\n",
    "\n",
    "            # loop through groups and plot profile data\n",
    "            for g in range(len(stat.classID.unique())):\n",
    "                # x is nodes\n",
    "                x = stat['nodeID'].unique()\n",
    "\n",
    "                # y is summary (mean, median, max, main) profile data\n",
    "                if summary_method == 'mean':\n",
    "                    y = stat[stat['classID'] == stat.classID.unique()[g]].groupby(['structureID','nodeID']).mean()[dm][t]\n",
    "                elif summary_method == 'median':\n",
    "                    y = stat[stat['classID'] == stat.classID.unique()[g]].groupby(['structureID','nodeID']).median()[dm][t]\n",
    "                elif summary_method == 'max':\n",
    "                    y = stat[stat['classID'] == stat.classID.unique()[g]].groupby(['structureID','nodeID']).max()[dm][t]\n",
    "                elif summary_method == 'min':\n",
    "                    y = stat[stat['classID'] == stat.classID.unique()[g]].groupby(['structureID','nodeID']).min()[dm][t]\n",
    "\n",
    "                # error bar is either: standard error of mean (sem), standard deviation (std)\n",
    "                if error_method == 'sem':\n",
    "                    err = stat[stat['classID'] == stat.classID.unique()[g]].groupby(['structureID','nodeID']).std()[dm][t] / np.sqrt(len(stat[stat['classID'] == stat.classID.unique()[g]]['subjectID'].unique()))\n",
    "                else:\n",
    "                    err = stat[stat['classID'] == stat.classID.unique()[g]].groupby(['structureID','nodeID']).std()[dm][t]\n",
    "\n",
    "                # plot summary\n",
    "                plt.plot(x,y,color=stat[stat['classID'] == stat.classID.unique()[g]]['colors'].unique()[0],linewidth=5,label=stat.classID.unique()[g])\n",
    "\n",
    "                # plot shaded error\n",
    "                plt.fill_between(x,y-err,y+err,alpha=0.4,color=stat[stat['classID'] == stat.classID.unique()[g]]['colors'].unique()[0],label='1 %s %s' %(error_method,stat.classID.unique()[g]))\n",
    "                plt.fill_between(x,y-(2*err),y+(2*err),alpha=0.2,color=stat[stat['classID'] == stat.classID.unique()[g]]['colors'].unique()[0],label='2 %s %s' %(error_method,stat.classID.unique()[g]))\n",
    "\n",
    "            # set up labels and ticks\n",
    "            plt.xlabel('Location',fontsize=18)\n",
    "            plt.ylabel(dm,fontsize=18)\n",
    "            plt.xticks([x[0],x[-1]],['Begin','End'],fontsize=16)\n",
    "            plt.legend(fontsize=12)\n",
    "            y_lim = plt.ylim()\n",
    "            plt.yticks([np.round(y_lim[0],2),np.mean(y_lim),np.round(y_lim[1],2)],fontsize=16)\n",
    "\n",
    "            # remove top and right spines from plot\n",
    "            p.axes.spines[\"top\"].set_visible(False)\n",
    "            p.axes.spines[\"right\"].set_visible(False)\n",
    "            ax = plt.gca()\n",
    "\n",
    "            # save image or show image\n",
    "            saveOrShowImg(dir_out,dm,dm,imgname)\n",
    "\n",
    "### generic data plots\n",
    "## structure average\n",
    "# uses matplotlib.pyplot's errobar function to plot group average data for each structure with errorbars. useful for publication worthy figure\n",
    "# requires stat to be formatted in similar way of AFQ_Brwoser and Yeatman et al 2018 () 'nodes.csv' files\n",
    "# groups is a list array of names of groups found in 'classID' of stat to plot\n",
    "# colors is a dictionary with the classID from groups set as the key and a color name as the value. will use these colors in profiles\n",
    "# tracks is a list array that will be looped through to make plots. if only one track is wanted, set structures=['structure_name'], with 'structure_name' being the name of the structure in the 'structureID' field of stat\n",
    "# stat is the pandas dataframe with all of the profile data. each row is a node for a track for a subject\n",
    "# diffusion_measures is a list array of the column measures found within stat. was developed with diffusion MRI metrics in mind, but can be any measure\n",
    "# summary_method is a string of either 'mean' to plot the average profile data, 'max' to plot max, 'min' to plot min, and 'median' to plot median\n",
    "# error_method is a string of either 'std' for the error bars to be set to the standard deviation or 'sem' for standard error of mean\n",
    "# dir_out and imgName are the directory where the figures should be saved and the name for the image. will save .pdf and .png\n",
    "# if want to view plot instead of save, set dir_out=\"\"\n",
    "def plotGroupStructureAverage(structures,tissue,stat,measures,summary_method,error_method,dir_out,img_name):\n",
    "\n",
    "    import os,sys\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy import stats\n",
    "\n",
    "    for dm in measures:\n",
    "        print(dm)\n",
    "\n",
    "        # generate figures\n",
    "        fig = plt.figure(figsize=(15,15))\n",
    "        fig.patch.set_visible(False)\n",
    "        p = plt.subplot()\n",
    "\n",
    "        # set y range\n",
    "        p.set_ylim([0,(len(structures)*len(stat.classID.unique()))+len(stat.classID.unique())])\n",
    "\n",
    "        # set spines and ticks, and labels\n",
    "        p.yaxis.set_ticks_position('left')\n",
    "        p.xaxis.set_ticks_position('bottom')\n",
    "        p.set_xlabel(dm,fontsize=18)\n",
    "        p.set_ylabel(\"Structures\",fontsize=18)\n",
    "        if len(stat.classID.unique()) < 3:\n",
    "            if len(stat.classID.unique()) == 2:\n",
    "                p.set_yticks(np.arange(1.5,(len(structures)*len(stat.classID.unique())),step=len(stat.classID.unique())))\n",
    "            else:\n",
    "                p.set_yticks(np.arange(1,len(structures)+1,step=1))\n",
    "        else:\n",
    "            p.set_yticks(np.arange((len(stat.classID.unique())-1),(len(structures)*len(stat.classID.unique())),step=len(stat.classID.unique())))\n",
    "        p.set_yticklabels(structures,fontsize=16)\n",
    "        plt.xticks(fontsize=16)\n",
    "\n",
    "        # set title\n",
    "        plt.title(\"%s Group-Summary: %s\" %(summary_method,dm),fontsize=20)\n",
    "\n",
    "        # loop through structures\n",
    "        for t in range(len(structures)):\n",
    "            # loop through groups\n",
    "            for g in range(len(stat.classID.unique())):\n",
    "                # x is summary (mean, median, max, main) profile data\n",
    "                if summary_method == 'mean':\n",
    "                    x = stat[stat.classID.str.contains(stat.classID.unique()[g])].groupby(tissue).mean()[dm][structures[t]]\n",
    "                elif summary_method == 'median':\n",
    "                    x = stat[stat.classID.str.contains(stat.classID.unique()[g])].groupby(tissue).median()[dm][structures[t]]\n",
    "                elif summary_method == 'max':\n",
    "                    x = stat[stat.classID.str.contains(stat.classID.unique()[g])].groupby(tissue).max()[dm][structures[t]]\n",
    "                elif summary_method == 'min':\n",
    "                    x = stat[stat.classID.str.contains(stat.classID.unique()[g])].groupby(tissue).min()[dm][structures[t]]\n",
    "\n",
    "                # y is location on y axis\n",
    "                y = (len(stat.classID.unique())*(t+1)-len(stat.classID.unique()))+(g+1)\n",
    "\n",
    "                # error bar is either: standard error of mean (sem), standard deviation (std)\n",
    "                if error_method == 'sem':\n",
    "                    err = stat[stat.classID.str.contains(stat.classID.unique()[g])].groupby(tissue).std()[dm][structures[t]] / np.sqrt(len(stat[stat.classID.str.contains(stat.classID.unique()[g])]['subjectID'].unique()))\n",
    "                else:\n",
    "                    err = stat[stat.classID.str.contains(stat.classID.unique()[g])].groupby(tissue).std()[dm][structures[t]]\n",
    "\n",
    "                # plot data\n",
    "                if t == 0:\n",
    "                    p.errorbar(x=x,y=y,xerr=err,barsabove=True,ecolor='black',color=stat[stat['classID'].str.contains(stat.classID.unique()[g])]['colors'].unique()[0],marker='o',ms=10,label=stat.classID.unique()[g])\n",
    "                else:\n",
    "                    p.errorbar(x=x,y=y,xerr=err,barsabove=True,ecolor='black',color=stat[stat['classID'].str.contains(stat.classID.unique()[g])]['colors'].unique()[0],marker='o',ms=10)\n",
    "\n",
    "        # add legend\n",
    "        plt.legend(fontsize=16)\n",
    "\n",
    "        # remove top and right spines from plot\n",
    "        p.axes.spines[\"top\"].set_visible(False)\n",
    "        p.axes.spines[\"right\"].set_visible(False)\n",
    "\n",
    "        # save image or show image\n",
    "        saveOrShowImg(dir_out,dm,dm,img_name)\n",
    "\n",
    "def violinPlots(x_measure,y_measure,hue_measure,data,summary,scale,inner,cmap,dir_out,img_name):\n",
    "    \n",
    "    if hue_measure:\n",
    "        violin = sns.violinplot(x=x_measure,y=y_measure,data=data,hue=hue_measure,scale=scale,inner=inner,palette=cmap)\n",
    "    else:\n",
    "        violin = sns.violinplot(x=x_measure,y=y_measure,data=data,scale=scale,inner=inner,palette=cmap,orientation='horizontal')\n",
    "\n",
    "    if summary == 'mean':\n",
    "        summary = data.groupby([x_measure])[y_measure].mean()\n",
    "    elif summary == 'median':\n",
    "        summary = data.groupby([x_measure])[y_measure].median()\n",
    "    elif summary == 'mode':\n",
    "        summary = data.groupby([x_measure])[y_measure].mode()\n",
    "    elif summary == 'max':\n",
    "        summary = data.groupby([x_measure])[y_measure].max()\n",
    "    elif summary == 'min':\n",
    "        summary = data.groupby([x_measure])[y_measure].min()\n",
    "\n",
    "#     for xtick in violin.get_xticks():\n",
    "#         violin.text(xtick,summary[xtick],np.round(summary[xtick],3),horizontalalignment='center',size='medium',color='w',weight='semibold')\n",
    "  \n",
    "    saveOrShowImg(dir_out,x_measure,y_measure,img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up variables\n",
      "setting up variables complete\n",
      "grabbing demographic data\n",
      "grabbing demographic data complete\n"
     ]
    }
   ],
   "source": [
    "### setting up variables and adding paths\n",
    "print(\"setting up variables\")\n",
    "topPath = \"./\"\n",
    "os.chdir(topPath)\n",
    "data_dir = topPath+'/data/'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "img_dir = topPath+'/img/'\n",
    "if not os.path.exists(img_dir):\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "groups = ['bl_generated','hcp_provided']\n",
    "colors_array = ['blue','gray']\n",
    "diff_micro_measures = ['ad','fa','md','rd','ndi','isovf','odi']\n",
    "diff_macro_measures = ['length','volume','count']\n",
    "print(\"setting up variables complete\")\n",
    "\n",
    "### grabbing subjects demographic data\n",
    "print(\"grabbing demographic data\")\n",
    "if os.path.isfile('./data/subjects_data.csv'):\n",
    "    subjects_data = pd.read_csv('./data/subjects_data.csv')\n",
    "else:\n",
    "    subjects_data = pd.read_csv('./subjects_demo.csv')\n",
    "    subjects_data['subjectID'] = [ str(int(np.float(f.strip('HCP')))) for f in subjects_data['subjectID']]\n",
    "    subjects_data.to_csv('./data/subjects_data.csv',index=False)\n",
    "print(\"grabbing demographic data complete\")\n",
    "\n",
    "colors = {}\n",
    "subjects = {}\n",
    "\n",
    "# loop through groups and identify subjects and set color schema for each group\n",
    "for g in range(len(groups)):\n",
    "    # set subjects array\n",
    "    subjects[groups[g]] =  subjects_data['subjectID']\n",
    "    subjects[groups[g]].sort_values()\n",
    "    # update subjects with HCP prefix to make plotting easier\n",
    "\n",
    "    # set colors array\n",
    "    colors_name = colors_array[g]\n",
    "    colors[groups[g]] = colors_array[g]\n",
    "\n",
    "### merge demo and subjects data\n",
    "# subjects_data = pd.merge(subjects_data,subjects_demo,on='subjectID')\n",
    "# subjects_data['classID'] = [ 'hcp' for f in range(len(subjects_data))]\n",
    "# subjects_data.to_csv(data_dir+'/subjects_data_demo.csv')\n",
    "\n",
    "# create subjects color dictionary\n",
    "colors_dict = createColorDictionary(subjects_data,'subjectID','colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_data.drop(columns={\"Unnamed: 0\"},inplace=True)\n",
    "subjects_data['subjectID'] = subjects_data['subjectID'].astype(object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectID</th>\n",
       "      <th>classID</th>\n",
       "      <th>colors</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_range</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103818</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103818</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105923</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105923</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111312</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>861456</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>877168</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>877168</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>917255</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>M</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>917255</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>M</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subjectID classID  colors gender age_range  age\n",
       "0     103818    test  orange      F     31-35   31\n",
       "1     103818  retest    blue      F     31-35   31\n",
       "2     105923    test  orange      F     31-35   31\n",
       "3     105923  retest    blue      F     31-35   31\n",
       "4     111312    test  orange      F     31-35   31\n",
       "..       ...     ...     ...    ...       ...  ...\n",
       "83    861456  retest    blue      F     31-35   31\n",
       "84    877168    test  orange      F     31-35   31\n",
       "85    877168  retest    blue      F     31-35   31\n",
       "86    917255    test  orange      M     31-35   31\n",
       "87    917255  retest    blue      M     31-35   31\n",
       "\n",
       "[88 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating brainlife: anatomical\n"
     ]
    }
   ],
   "source": [
    "### freesurfer validation analysis: hcp freesurfer vs bl freesurfer\n",
    "print(\"validating brainlife: anatomical\")\n",
    "# grab data: desikan killany\n",
    "bl_generated_aparc_test = collectData('neuro/parc-stats','freesurfer',['test','aparc.a2009s','bl_generated'],\"cortex.csv\",subjects_data,colors,data_dir+\"/bl_generated_freesurfer_aparc_test.csv\")\n",
    "hcp_provided_aparc_test = collectData('neuro/parc-stats','freesurfer',['test','aparc.a2009s','hcp_provided'],\"cortex.csv\",subjects_data,colors,data_dir+\"/hcp_provided_freesurfer_aparc_test.csv\")\n",
    "bl_generated_aparc_test['classID'] = [ 'bl_generated' for f in bl_generated_aparc_test['subjectID']]\n",
    "hcp_provided_aparc_test['classID'] = [ 'hcp_provided' for f in hcp_provided_aparc_test['subjectID']]\n",
    "aparc_validity = pd.concat([bl_generated_aparc_test,hcp_provided_aparc_test])\n",
    "aparc_validity = aparc_validity.drop_duplicates()\n",
    "aparc_validity.to_csv('desikian_killany_aparc_validity_hcp_test_data.csv',index=False)\n",
    "\n",
    "# plot data\n",
    "singleplotScatter(\"\",aparc_validity.loc[aparc_validity['classID'] == 'hcp_provided'],aparc_validity.loc[aparc_validity['classID'] == 'bl_generated'],'average_thickness_mm','average_thickness_mm',False,'structureID','structureID','ravel','linreg',True,img_dir,'aparc_validity_hcp_test_thickness')\n",
    "singleplotScatter(\"\",aparc_validity.loc[aparc_validity['classID'] == 'hcp_provided'],aparc_validity.loc[aparc_validity['classID'] == 'bl_generated'],'surface_area_mm^2','surface_area_mm^2',False,'structureID','structureID','ravel','linreg',True,img_dir,'aparc_validity_hcp_test_surface_area')\n",
    "singleplotScatter(\"\",aparc_validity.loc[aparc_validity['classID'] == 'hcp_provided'],aparc_validity.loc[aparc_validity['classID'] == 'bl_generated'],'gray_matter_volume_mm^3','gray_matter_volume_mm^3',False,'structureID','structureID','ravel','linreg',True,img_dir,'aparc_validity_hcp_test_volume')\n",
    "\n",
    "# grab data: hcp-mmp\n",
    "bl_generated_glasser_test = collectData('neuro/parc-stats','surface',['test','glasser','bl_generated'],\"cortex.csv\",subjects_data,colors,data_dir+\"/bl_generated_freesurfer_glasser_test.csv\")\n",
    "hcp_provided_glasser_test = collectData('neuro/parc-stats','surface',['test','glasser','hcp_provided'],\"cortex.csv\",subjects_data,colors,data_dir+\"/hcp_provided_freesurfer_glasser_test.csv\")\n",
    "bl_generated_glasser_test['classID'] = [ 'bl_generated' for f in bl_generated_glasser_test['subjectID']]\n",
    "hcp_provided_glasser_test['classID'] = [ 'hcp_provided' for f in hcp_provided_glasser_test['subjectID']]\n",
    "\n",
    "# concat and clean\n",
    "glasser_validity = pd.concat([bl_generated_glasser_test,hcp_provided_glasser_test])\n",
    "glasser_validity = glasser_validity[glasser_validity['structureID'] != 'lh_???']\n",
    "glasser_validity = glasser_validity[glasser_validity['structureID'] != 'rh_???']\n",
    "glasser_validity = glasser_validity[~glasser_validity.structureID.str.contains('unknown')]\n",
    "glasser_validity = glasser_validity[~glasser_validity.structureID.str.contains('_H_ROI')]\n",
    "glasser_validity = glasser_validity.drop_duplicates()\n",
    "glasser_validity.to_csv('hcp_mmp_glasser_validity_hcp_test_data.csv',index=False)\n",
    "\n",
    "# plot data\n",
    "singleplotScatter(\"\",glasser_validity.loc[glasser_validity['classID'] == 'hcp_provided'],glasser_validity.loc[glasser_validity['classID'] == 'bl_generated'],'average_thickness_mm','average_thickness_mm',False,'structureID','structureID','ravel','linreg',True,img_dir,'glasser_validity_hcp_test_thickness')\n",
    "singleplotScatter(\"\",glasser_validity.loc[glasser_validity['classID'] == 'hcp_provided'],glasser_validity.loc[glasser_validity['classID'] == 'bl_generated'],'surface_area_mm^2','surface_area_mm^2',False,'structureID','structureID','ravel','linreg',True,img_dir,'glasser_validity_hcp_test_surface_area')\n",
    "singleplotScatter(\"\",glasser_validity.loc[glasser_validity['classID'] == 'hcp_provided'],glasser_validity.loc[glasser_validity['classID'] == 'bl_generated'],'gray_matter_volume_mm^3','gray_matter_volume_mm^3',False,'structureID','structureID','ravel','linreg',True,img_dir,'glasser_validity_hcp_test_volume')\n",
    "\n",
    "print(\"validating brainlife complete: anatomical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### diffusion validation analysis: hcp preprocessed dwi vs bl preprocessed dwi\n",
    "print(\"validating brainlife: diffusion\")\n",
    "# grab data: desikan killany\n",
    "# bl_generated_aparc_test = collectData('neuro/parc-stats','freesurfer',['test','aparc.a2009s','bl_generated'],\"cortex.csv\",subjects_data,colors,data_dir+\"/bl_generated_freesurfer_aparc_test.csv\")\n",
    "# hcp_provided_aparc_test = collectData('neuro/parc-stats','freesurfer',['test','aparc.a2009s','hcp_provided'],\"cortex.csv\",subjects_data,colors,data_dir+\"/hcp_provided_freesurfer_aparc_test.csv\")\n",
    "# bl_generated_aparc_test['classID'] = [ 'bl_generated' for f in bl_generated_aparc_test['subjectID']]\n",
    "# hcp_provided_aparc_test['classID'] = [ 'hcp_provided' for f in hcp_provided_aparc_test['subjectID']]\n",
    "# aparc_validity = pd.concat([bl_generated_aparc_test,hcp_provided_aparc_test])\n",
    "# aparc_validity = aparc_validity.drop_duplicates()\n",
    "# aparc_validity.to_csv('desikian_killany_aparc_validity_hcp_test_data.csv',index=False)\n",
    "\n",
    "# # plot data\n",
    "# singleplotScatter(\"\",aparc_validity.loc[aparc_validity['classID'] == 'hcp_provided'],aparc_validity.loc[aparc_validity['classID'] == 'bl_generated'],'average_thickness_mm','average_thickness_mm',False,'structureID','structureID','ravel','linreg',True,img_dir,'aparc_validity_hcp_test_thickness')\n",
    "# singleplotScatter(\"\",aparc_validity.loc[aparc_validity['classID'] == 'hcp_provided'],aparc_validity.loc[aparc_validity['classID'] == 'bl_generated'],'surface_area_mm^2','surface_area_mm^2',False,'structureID','structureID','ravel','linreg',True,img_dir,'aparc_validity_hcp_test_surface_area')\n",
    "# singleplotScatter(\"\",aparc_validity.loc[aparc_validity['classID'] == 'hcp_provided'],aparc_validity.loc[aparc_validity['classID'] == 'bl_generated'],'gray_matter_volume_mm^3','gray_matter_volume_mm^3',False,'structureID','structureID','ravel','linreg',True,img_dir,'aparc_validity_hcp_test_volume')\n",
    "\n",
    "# # grab data: hcp-mmp\n",
    "# bl_generated_glasser_test = collectData('neuro/parc-stats','surface',['test','glasser','bl_generated'],\"cortex.csv\",subjects_data,colors,data_dir+\"/bl_generated_freesurfer_glasser_test.csv\")\n",
    "# hcp_provided_glasser_test = collectData('neuro/parc-stats','surface',['test','glasser','hcp_provided'],\"cortex.csv\",subjects_data,colors,data_dir+\"/hcp_provided_freesurfer_glasser_test.csv\")\n",
    "# bl_generated_glasser_test['classID'] = [ 'bl_generated' for f in bl_generated_glasser_test['subjectID']]\n",
    "# hcp_provided_glasser_test['classID'] = [ 'hcp_provided' for f in hcp_provided_glasser_test['subjectID']]\n",
    "\n",
    "# # concat and clean\n",
    "# glasser_validity = pd.concat([bl_generated_glasser_test,hcp_provided_glasser_test])\n",
    "# glasser_validity = glasser_validity[glasser_validity['structureID'] != 'lh_???']\n",
    "# glasser_validity = glasser_validity[glasser_validity['structureID'] != 'rh_???']\n",
    "# glasser_validity = glasser_validity[~glasser_validity.structureID.str.contains('unknown')]\n",
    "# glasser_validity = glasser_validity[~glasser_validity.structureID.str.contains('_H_ROI')]\n",
    "# glasser_validity = glasser_validity.drop_duplicates()\n",
    "# glasser_validity.to_csv('hcp_mmp_glasser_validity_hcp_test_data.csv',index=False)\n",
    "\n",
    "# # plot data\n",
    "# singleplotScatter(\"\",glasser_validity.loc[glasser_validity['classID'] == 'hcp_provided'],glasser_validity.loc[glasser_validity['classID'] == 'bl_generated'],'average_thickness_mm','average_thickness_mm',False,'structureID','structureID','ravel','linreg',True,img_dir,'glasser_validity_hcp_test_thickness')\n",
    "# singleplotScatter(\"\",glasser_validity.loc[glasser_validity['classID'] == 'hcp_provided'],glasser_validity.loc[glasser_validity['classID'] == 'bl_generated'],'surface_area_mm^2','surface_area_mm^2',False,'structureID','structureID','ravel','linreg',True,img_dir,'glasser_validity_hcp_test_surface_area')\n",
    "# singleplotScatter(\"\",glasser_validity.loc[glasser_validity['classID'] == 'hcp_provided'],glasser_validity.loc[glasser_validity['classID'] == 'bl_generated'],'gray_matter_volume_mm^3','gray_matter_volume_mm^3',False,'structureID','structureID','ravel','linreg',True,img_dir,'glasser_validity_hcp_test_volume')\n",
    "\n",
    "print(\"validating brainlife complete: diffusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### diffusion validation analysis: hcp preprocessed fmri vs bl preprocessed fmri\n",
    "print(\"validating brainlife: fmri\")\n",
    "# grab data: desikan killany\n",
    "# bl_generated_aparc_test = collectData('neuro/parc-stats','freesurfer',['test','aparc.a2009s','bl_generated'],\"cortex.csv\",subjects_data,colors,data_dir+\"/bl_generated_freesurfer_aparc_test.csv\")\n",
    "# hcp_provided_aparc_test = collectData('neuro/parc-stats','freesurfer',['test','aparc.a2009s','hcp_provided'],\"cortex.csv\",subjects_data,colors,data_dir+\"/hcp_provided_freesurfer_aparc_test.csv\")\n",
    "# bl_generated_aparc_test['classID'] = [ 'bl_generated' for f in bl_generated_aparc_test['subjectID']]\n",
    "# hcp_provided_aparc_test['classID'] = [ 'hcp_provided' for f in hcp_provided_aparc_test['subjectID']]\n",
    "# aparc_validity = pd.concat([bl_generated_aparc_test,hcp_provided_aparc_test])\n",
    "# aparc_validity = aparc_validity.drop_duplicates()\n",
    "# aparc_validity.to_csv('desikian_killany_aparc_validity_hcp_test_data.csv',index=False)\n",
    "\n",
    "# # plot data\n",
    "# singleplotScatter(\"\",aparc_validity.loc[aparc_validity['classID'] == 'hcp_provided'],aparc_validity.loc[aparc_validity['classID'] == 'bl_generated'],'average_thickness_mm','average_thickness_mm',False,'structureID','structureID','ravel','linreg',True,img_dir,'aparc_validity_hcp_test_thickness')\n",
    "# singleplotScatter(\"\",aparc_validity.loc[aparc_validity['classID'] == 'hcp_provided'],aparc_validity.loc[aparc_validity['classID'] == 'bl_generated'],'surface_area_mm^2','surface_area_mm^2',False,'structureID','structureID','ravel','linreg',True,img_dir,'aparc_validity_hcp_test_surface_area')\n",
    "# singleplotScatter(\"\",aparc_validity.loc[aparc_validity['classID'] == 'hcp_provided'],aparc_validity.loc[aparc_validity['classID'] == 'bl_generated'],'gray_matter_volume_mm^3','gray_matter_volume_mm^3',False,'structureID','structureID','ravel','linreg',True,img_dir,'aparc_validity_hcp_test_volume')\n",
    "\n",
    "# # grab data: hcp-mmp\n",
    "# bl_generated_glasser_test = collectData('neuro/parc-stats','surface',['test','glasser','bl_generated'],\"cortex.csv\",subjects_data,colors,data_dir+\"/bl_generated_freesurfer_glasser_test.csv\")\n",
    "# hcp_provided_glasser_test = collectData('neuro/parc-stats','surface',['test','glasser','hcp_provided'],\"cortex.csv\",subjects_data,colors,data_dir+\"/hcp_provided_freesurfer_glasser_test.csv\")\n",
    "# bl_generated_glasser_test['classID'] = [ 'bl_generated' for f in bl_generated_glasser_test['subjectID']]\n",
    "# hcp_provided_glasser_test['classID'] = [ 'hcp_provided' for f in hcp_provided_glasser_test['subjectID']]\n",
    "\n",
    "# # concat and clean\n",
    "# glasser_validity = pd.concat([bl_generated_glasser_test,hcp_provided_glasser_test])\n",
    "# glasser_validity = glasser_validity[glasser_validity['structureID'] != 'lh_???']\n",
    "# glasser_validity = glasser_validity[glasser_validity['structureID'] != 'rh_???']\n",
    "# glasser_validity = glasser_validity[~glasser_validity.structureID.str.contains('unknown')]\n",
    "# glasser_validity = glasser_validity[~glasser_validity.structureID.str.contains('_H_ROI')]\n",
    "# glasser_validity = glasser_validity.drop_duplicates()\n",
    "# glasser_validity.to_csv('hcp_mmp_glasser_validity_hcp_test_data.csv',index=False)\n",
    "\n",
    "# # plot data\n",
    "# singleplotScatter(\"\",glasser_validity.loc[glasser_validity['classID'] == 'hcp_provided'],glasser_validity.loc[glasser_validity['classID'] == 'bl_generated'],'average_thickness_mm','average_thickness_mm',False,'structureID','structureID','ravel','linreg',True,img_dir,'glasser_validity_hcp_test_thickness')\n",
    "# singleplotScatter(\"\",glasser_validity.loc[glasser_validity['classID'] == 'hcp_provided'],glasser_validity.loc[glasser_validity['classID'] == 'bl_generated'],'surface_area_mm^2','surface_area_mm^2',False,'structureID','structureID','ravel','linreg',True,img_dir,'glasser_validity_hcp_test_surface_area')\n",
    "# singleplotScatter(\"\",glasser_validity.loc[glasser_validity['classID'] == 'hcp_provided'],glasser_validity.loc[glasser_validity['classID'] == 'bl_generated'],'gray_matter_volume_mm^3','gray_matter_volume_mm^3',False,'structureID','structureID','ravel','linreg',True,img_dir,'glasser_validity_hcp_test_volume')\n",
    "\n",
    "print(\"validating brainlife complete: fmri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectID</th>\n",
       "      <th>classID</th>\n",
       "      <th>colors</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_range</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103818</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103818</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105923</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105923</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111312</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>861456</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>877168</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>877168</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>F</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>917255</td>\n",
       "      <td>test</td>\n",
       "      <td>orange</td>\n",
       "      <td>M</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>917255</td>\n",
       "      <td>retest</td>\n",
       "      <td>blue</td>\n",
       "      <td>M</td>\n",
       "      <td>31-35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subjectID classID  colors gender age_range  age\n",
       "0      103818    test  orange      F     31-35   31\n",
       "1      103818  retest    blue      F     31-35   31\n",
       "2      105923    test  orange      F     31-35   31\n",
       "3      105923  retest    blue      F     31-35   31\n",
       "4      111312    test  orange      F     31-35   31\n",
       "..        ...     ...     ...    ...       ...  ...\n",
       "83     861456  retest    blue      F     31-35   31\n",
       "84     877168    test  orange      F     31-35   31\n",
       "85     877168  retest    blue      F     31-35   31\n",
       "86     917255    test  orange      M     31-35   31\n",
       "87     917255  retest    blue      M     31-35   31\n",
       "\n",
       "[88 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### cortical data reliability: test-retest with hcp-freesurfer\n",
    "print(\"grabbing aparc a2009s data\")\n",
    "\n",
    "### freesurfer annotation statistics - bl generated\n",
    "print(\"grabbing bl generated aparc a2009s data\")\n",
    "# grab data\n",
    "aparc_stats_bl = collectData(topPath,\"parc-freesurfer-bl\",\"cortex.csv\",data_dir,groups,subjects,'generated-a2009s')\n",
    "\n",
    "# plot data\n",
    "for measures in structural_measures:\n",
    "    print(measures)\n",
    "    singleplotScatter(colors_dict,aparc_stats_bl[aparc_stats_bl['classID'] == groups[0]],aparc_stats_bl[aparc_stats_bl['classID'] == groups[1]],measures,measures,'structureID','subjectID','ravel','linreg',True,img_dir,\"aparc_stats_bl_scatter\")\n",
    "\n",
    "### glasser annotation statistics\n",
    "print(\"grabbing glasser data\")\n",
    "# grab data\n",
    "glasser_stats_bl = collectData(topPath,\"parc-glasser-bl\",\"cortex.csv\",data_dir,groups,subjects,'bl-generated')\n",
    "\n",
    "# clean up data\n",
    "glasser_stats_bl = glasser_stats_bl[glasser_stats_bl['structureID'] != 'lh_???']\n",
    "glasser_stats_bl = glasser_stats_bl[glasser_stats_bl['structureID'] != 'rh_???'] \n",
    "glasser_stats_bl = glasser_stats_bl[~glasser_stats_bl.structureID.str.contains('unknown')]\n",
    "structureList = []\n",
    "for i in glasser_stats_bl['structureID'].unique():\n",
    "    if len(glasser_stats_bl[glasser_stats_bl['structureID'] == i].subjectID) < len(groups) * len(glasser_stats_bl['subjectID'].unique()):\n",
    "        print('%s is missing in all subjects' %i)\n",
    "    else:\n",
    "        structureList = np.append(structureList,i)\n",
    "glasser_stats_bl = glasser_stats_bl.loc[glasser_stats_bl['structureID'].isin(structureList)]\n",
    "glasser_stats_bl.to_csv(data_dir+'/parc-glasser-bl-cleaned.csv')\n",
    "\n",
    "# plot data\n",
    "for measures in structural_measures:\n",
    "    print(measures)\n",
    "    singleplotScatter(colors_dict,glasser_stats_bl[glasser_stats_bl['classID'] == groups[0]],glasser_stats_bl[glasser_stats_bl['classID'] == groups[1]],measures,measures,'structureID','subjectID','ravel','linreg',True,img_dir,\"glasser_stats_bl_scatter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmri validity\n",
    "# fmri_yeo_network_test = collectData('generic/network','measurements',['test','bl'],'network.json.gz',subjects_data,colors,data_dir+\"/hcp_provided_fmri_yeo_test.csv\")\n",
    "# fmri_yeo_network_retest = collectData('generic/network','measurements',['retest','bl'],'network.json.gz',subjects_data,colors,data_dir+\"/hcp_provided_fmri_yeo_retest.csv\")\n",
    "\n",
    "\n",
    "fmri_yeo_network_test['classID'] = [ 'hcp-test' for f in fmri_yeo_network_test['subjectID'] ]\n",
    "fmri_yeo_network_retest['classID'] = [ 'hcp-retest' for f in fmri_yeo_network_retest['subjectID'] ]\n",
    "fmri_yeo_network = pd.concat([fmri_yeo_network_test,fmri_yeo_network_retest.loc[fmri_yeo_network_retest['subjectID'].isin(fmri_yeo_network_test.subjectID.unique())]])\n",
    "\n",
    "fmri_avg_degree = [ f['Avg. Degree'] for f in fmri_yeo_network['metadata'] ]\n",
    "fmri_avg_strength = [ f['Avg. Strength'] for f in fmri_yeo_network['metadata'] ]\n",
    "\n",
    "fmri_yeo_network['average_degree'] = fmri_avg_degree\n",
    "fmri_yeo_network['average_strength'] = fmri_avg_strength\n",
    "\n",
    "\n",
    "singleplotScatter('',fmri_yeo_network.loc[fmri_yeo_network['classID'] == 'hcp-test'],fmri_yeo_network.loc[fmri_yeo_network['classID'] == 'hcp-retest'],'average_degree','average_degree',False,'classID','classID','ravel','linreg',True,img_dir,'fmri_yeo_average_degree_reliability')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmri test-retest\n",
    "# fmri_yeo_test = collectData('generic/network','measurements',['test','bl'],'network.json.gz',subjects_data,colors,data_dir+\"/hcp_provided_fmri_yeo_reliability_test.csv\")\n",
    "# fmri_yeo_test['classID'] = ['test' for f in fmri_yeo_test['subjectID']]\n",
    "# fmri_yeo_test.drop_duplicates('subjectID',inplace=True)\n",
    "\n",
    "# fmri_yeo_retest = collectData('generic/network','measurements',['retest','bl'],'network.json.gz',subjects_data,colors,data_dir+\"/hcp_provided_fmri_yeo_reliability_retest.csv\")\n",
    "# fmri_yeo_retest['classID'] = ['retest' for f in fmri_yeo_retest['subjectID']]\n",
    "# fmri_yeo_retest.drop_duplicates('subjectID',inplace=True)\n",
    "\n",
    "fmri_yeo_test_node_degree = []\n",
    "fmri_yeo_test_subjects = []\n",
    "for i in fmri_yeo_test.subjectID.unique():\n",
    "    for j in fmri_yeo_test.loc[fmri_yeo_test['subjectID'] == i]['nodes'].reset_index(drop=True)[0]:\n",
    "        fmri_yeo_test_subjects = np.append(fmri_yeo_test_subjects,i)\n",
    "        fmri_yeo_test_node_degree = np.append(fmri_yeo_test_node_degree,fmri_yeo_test.loc[fmri_yeo_test['subjectID'] == i]['nodes'].reset_index(drop=True)[0][j]['metadata']['Degree'])\n",
    "        \n",
    "fmri_yeo_retest_node_degree = []\n",
    "fmri_yeo_retest_subjects = []\n",
    "for i in fmri_yeo_test.subjectID.unique():\n",
    "    for j in fmri_yeo_retest.loc[fmri_yeo_retest['subjectID'] == i]['nodes'].reset_index(drop=True)[0]:\n",
    "        fmri_yeo_retest_subjects = np.append(fmri_yeo_retest_subjects,i)\n",
    "        fmri_yeo_retest_node_degree = np.append(fmri_yeo_retest_node_degree,fmri_yeo_retest.loc[fmri_yeo_retest['subjectID'] == i]['nodes'].reset_index(drop=True)[0][j]['metadata']['Degree'])\n",
    "        \n",
    "node_degree_validity = pd.DataFrame()\n",
    "node_degree_validity['degree'] = np.append(fmri_yeo_test_node_degree,fmri_yeo_retest_node_degree)\n",
    "node_degree_validity['classID'] = np.append([ 'test' for f in fmri_yeo_test_node_degree],[ 'retest' for f in fmri_yeo_retest_node_degree])\n",
    "node_degree_validity['subjectID'] = np.append(fmri_yeo_test_subjects,fmri_yeo_retest_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleplotScatter('',node_degree_validity.loc[node_degree_validity['classID'] == 'test'],node_degree_validity.loc[node_degree_validity['classID'] == 'retest'],'degree','degree',False,'subjectID','subjectID','ravel','linreg',True,img_dir,'fmri_yeo_test_retest_reliability')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'label': 'ROI_1',\n",
       "  'metadata': {'column_name': 'ROI_1',\n",
       "   'label_index': '1',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 16,\n",
       "   'Strength': 4.61842802013915,\n",
       "   'ClusteringCoefficient': 0.325,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 126.47704958515878,\n",
       "   'BetweenessCentralityWeighted': 272.0}},\n",
       " '1': {'label': 'ROI_2',\n",
       "  'metadata': {'column_name': 'ROI_2',\n",
       "   'label_index': '2',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 20,\n",
       "   'Strength': 8.687688807266449,\n",
       "   'ClusteringCoefficient': 0.49473684210526303,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 53.11951737557964,\n",
       "   'BetweenessCentralityWeighted': 66.0}},\n",
       " '2': {'label': 'ROI_3',\n",
       "  'metadata': {'column_name': 'ROI_3',\n",
       "   'label_index': '3',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 8.045985096512268,\n",
       "   'ClusteringCoefficient': 0.704761904761904,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 29.684622812947303,\n",
       "   'BetweenessCentralityWeighted': 17.0}},\n",
       " '3': {'label': 'ROI_4',\n",
       "  'metadata': {'column_name': 'ROI_4',\n",
       "   'label_index': '4',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 17,\n",
       "   'Strength': 7.879081668064459,\n",
       "   'ClusteringCoefficient': 0.544117647058823,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 50.61539749545263,\n",
       "   'BetweenessCentralityWeighted': 48.0}},\n",
       " '4': {'label': 'ROI_5',\n",
       "  'metadata': {'column_name': 'ROI_5',\n",
       "   'label_index': '5',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 12,\n",
       "   'Strength': 5.435848816650208,\n",
       "   'ClusteringCoefficient': 0.636363636363636,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 34.35064551451374,\n",
       "   'BetweenessCentralityWeighted': 37.0}},\n",
       " '5': {'label': 'ROI_6',\n",
       "  'metadata': {'column_name': 'ROI_6',\n",
       "   'label_index': '6',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 10,\n",
       "   'Strength': 4.851764258925039,\n",
       "   'ClusteringCoefficient': 0.5777777777777771,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 29.909298412679348,\n",
       "   'BetweenessCentralityWeighted': 17.0}},\n",
       " '6': {'label': 'ROI_7',\n",
       "  'metadata': {'column_name': 'ROI_7',\n",
       "   'label_index': '7',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 20,\n",
       "   'Strength': 7.499527949501417,\n",
       "   'ClusteringCoefficient': 0.42631578947368404,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 290.5538154495378,\n",
       "   'BetweenessCentralityWeighted': 269.0}},\n",
       " '7': {'label': 'ROI_8',\n",
       "  'metadata': {'column_name': 'ROI_8',\n",
       "   'label_index': '8',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 18,\n",
       "   'Strength': 6.948995847477849,\n",
       "   'ClusteringCoefficient': 0.7450980392156861,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 29.114867897527493,\n",
       "   'BetweenessCentralityWeighted': 38.0}},\n",
       " '8': {'label': 'ROI_9',\n",
       "  'metadata': {'column_name': 'ROI_9',\n",
       "   'label_index': '9',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 18,\n",
       "   'Strength': 7.472640104637257,\n",
       "   'ClusteringCoefficient': 0.725490196078431,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 25.463666761368884,\n",
       "   'BetweenessCentralityWeighted': 26.0}},\n",
       " '9': {'label': 'ROI_10',\n",
       "  'metadata': {'column_name': 'ROI_10',\n",
       "   'label_index': '10',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 6,\n",
       "   'Strength': 1.778487572902598,\n",
       "   'ClusteringCoefficient': 0.6000000000000001,\n",
       "   'Coreness': 6,\n",
       "   'BetweenessCentrality': 2.803814793452195,\n",
       "   'BetweenessCentralityWeighted': 7.0}},\n",
       " '10': {'label': 'ROI_11',\n",
       "  'metadata': {'column_name': 'ROI_11',\n",
       "   'label_index': '11',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 26,\n",
       "   'Strength': 10.089260730164353,\n",
       "   'ClusteringCoefficient': 0.59076923076923,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 70.75299377177994,\n",
       "   'BetweenessCentralityWeighted': 157.0}},\n",
       " '11': {'label': 'ROI_12',\n",
       "  'metadata': {'column_name': 'ROI_12',\n",
       "   'label_index': '12',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 18,\n",
       "   'Strength': 7.944015974268051,\n",
       "   'ClusteringCoefficient': 0.542483660130718,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 54.534377227472476,\n",
       "   'BetweenessCentralityWeighted': 34.0}},\n",
       " '12': {'label': 'ROI_13',\n",
       "  'metadata': {'column_name': 'ROI_13',\n",
       "   'label_index': '13',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 22,\n",
       "   'Strength': 9.90456082883249,\n",
       "   'ClusteringCoefficient': 0.48051948051948,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 167.10491819049912,\n",
       "   'BetweenessCentralityWeighted': 158.0}},\n",
       " '13': {'label': 'ROI_14',\n",
       "  'metadata': {'column_name': 'ROI_14',\n",
       "   'label_index': '14',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 12,\n",
       "   'Strength': 5.255135717883293,\n",
       "   'ClusteringCoefficient': 0.53030303030303,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 84.30152239640076,\n",
       "   'BetweenessCentralityWeighted': 47.0}},\n",
       " '14': {'label': 'ROI_15',\n",
       "  'metadata': {'column_name': 'ROI_15',\n",
       "   'label_index': '15',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 6.406272387316513,\n",
       "   'ClusteringCoefficient': 0.628571428571428,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 50.82318281953917,\n",
       "   'BetweenessCentralityWeighted': 33.0}},\n",
       " '15': {'label': 'ROI_16',\n",
       "  'metadata': {'column_name': 'ROI_16',\n",
       "   'label_index': '16',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 31,\n",
       "   'Strength': 12.102140189025247,\n",
       "   'ClusteringCoefficient': 0.38279569892473103,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 500.7307154956512,\n",
       "   'BetweenessCentralityWeighted': 443.0}},\n",
       " '16': {'label': 'ROI_17',\n",
       "  'metadata': {'column_name': 'ROI_17',\n",
       "   'label_index': '17',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 19,\n",
       "   'Strength': 6.872360954465226,\n",
       "   'ClusteringCoefficient': 0.502923976608187,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 108.10073225156461,\n",
       "   'BetweenessCentralityWeighted': 125.0}},\n",
       " '17': {'label': 'ROI_18',\n",
       "  'metadata': {'column_name': 'ROI_18',\n",
       "   'label_index': '18',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 27,\n",
       "   'Strength': 10.51473214513318,\n",
       "   'ClusteringCoefficient': 0.529914529914529,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 97.09536079565136,\n",
       "   'BetweenessCentralityWeighted': 108.0}},\n",
       " '18': {'label': 'ROI_19',\n",
       "  'metadata': {'column_name': 'ROI_19',\n",
       "   'label_index': '19',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 22,\n",
       "   'Strength': 9.487471987426881,\n",
       "   'ClusteringCoefficient': 0.6796536796536791,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 54.86477997721124,\n",
       "   'BetweenessCentralityWeighted': 75.0}},\n",
       " '19': {'label': 'ROI_20',\n",
       "  'metadata': {'column_name': 'ROI_20',\n",
       "   'label_index': '20',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 26,\n",
       "   'Strength': 11.333333368272472,\n",
       "   'ClusteringCoefficient': 0.612307692307692,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 41.729105313686716,\n",
       "   'BetweenessCentralityWeighted': 33.0}},\n",
       " '20': {'label': 'ROI_21',\n",
       "  'metadata': {'column_name': 'ROI_21',\n",
       "   'label_index': '21',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 21,\n",
       "   'Strength': 8.429309623401625,\n",
       "   'ClusteringCoefficient': 0.661904761904761,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 56.44425057509494,\n",
       "   'BetweenessCentralityWeighted': 24.0}},\n",
       " '21': {'label': 'ROI_22',\n",
       "  'metadata': {'column_name': 'ROI_22',\n",
       "   'label_index': '22',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 4,\n",
       "   'Strength': 1.285363656834007,\n",
       "   'ClusteringCoefficient': 0.5,\n",
       "   'Coreness': 3,\n",
       "   'BetweenessCentrality': 13.949189264486579,\n",
       "   'BetweenessCentralityWeighted': 15.0}},\n",
       " '22': {'label': 'ROI_23',\n",
       "  'metadata': {'column_name': 'ROI_23',\n",
       "   'label_index': '23',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 31,\n",
       "   'Strength': 11.43891610556974,\n",
       "   'ClusteringCoefficient': 0.50752688172043,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 146.114897443843,\n",
       "   'BetweenessCentralityWeighted': 158.0}},\n",
       " '23': {'label': 'ROI_24',\n",
       "  'metadata': {'column_name': 'ROI_24',\n",
       "   'label_index': '24',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 26,\n",
       "   'Strength': 10.464548698000588,\n",
       "   'ClusteringCoefficient': 0.563076923076923,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 82.6641704166743,\n",
       "   'BetweenessCentralityWeighted': 61.0}},\n",
       " '24': {'label': 'ROI_25',\n",
       "  'metadata': {'column_name': 'ROI_25',\n",
       "   'label_index': '25',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 4,\n",
       "   'Strength': 1.23983913278196,\n",
       "   'ClusteringCoefficient': 0.33333333333333304,\n",
       "   'Coreness': 4,\n",
       "   'BetweenessCentrality': 8.603425566212003,\n",
       "   'BetweenessCentralityWeighted': 16.0}},\n",
       " '25': {'label': 'ROI_26',\n",
       "  'metadata': {'column_name': 'ROI_26',\n",
       "   'label_index': '26',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 23,\n",
       "   'Strength': 10.489021898722312,\n",
       "   'ClusteringCoefficient': 0.513833992094861,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 97.70277400512427,\n",
       "   'BetweenessCentralityWeighted': 55.0}},\n",
       " '26': {'label': 'ROI_27',\n",
       "  'metadata': {'column_name': 'ROI_27',\n",
       "   'label_index': '27',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 18,\n",
       "   'Strength': 5.67726700744611,\n",
       "   'ClusteringCoefficient': 0.39215686274509803,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 129.91832203578136,\n",
       "   'BetweenessCentralityWeighted': 149.0}},\n",
       " '27': {'label': 'ROI_28',\n",
       "  'metadata': {'column_name': 'ROI_28',\n",
       "   'label_index': '28',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 5.47913638655525,\n",
       "   'ClusteringCoefficient': 0.47619047619047605,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 51.137276272792015,\n",
       "   'BetweenessCentralityWeighted': 67.0}},\n",
       " '28': {'label': 'ROI_29',\n",
       "  'metadata': {'column_name': 'ROI_29',\n",
       "   'label_index': '29',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 18,\n",
       "   'Strength': 6.043320822706579,\n",
       "   'ClusteringCoefficient': 0.620915032679738,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 17.519144236512954,\n",
       "   'BetweenessCentralityWeighted': 61.0}},\n",
       " '29': {'label': 'ROI_30',\n",
       "  'metadata': {'column_name': 'ROI_30',\n",
       "   'label_index': '30',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 10,\n",
       "   'Strength': 2.7912330086697343,\n",
       "   'ClusteringCoefficient': 0.24444444444444402,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 68.78161252344395,\n",
       "   'BetweenessCentralityWeighted': 158.0}},\n",
       " '30': {'label': 'ROI_31',\n",
       "  'metadata': {'column_name': 'ROI_31',\n",
       "   'label_index': '31',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 19,\n",
       "   'Strength': 7.6290068377378475,\n",
       "   'ClusteringCoefficient': 0.508771929824561,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 63.63406377102936,\n",
       "   'BetweenessCentralityWeighted': 99.0}},\n",
       " '31': {'label': 'ROI_32',\n",
       "  'metadata': {'column_name': 'ROI_32',\n",
       "   'label_index': '32',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 18,\n",
       "   'Strength': 6.741891973770489,\n",
       "   'ClusteringCoefficient': 0.44444444444444403,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 114.31853397712177,\n",
       "   'BetweenessCentralityWeighted': 72.0}},\n",
       " '32': {'label': 'ROI_33',\n",
       "  'metadata': {'column_name': 'ROI_33',\n",
       "   'label_index': '33',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 28,\n",
       "   'Strength': 10.812082896676547,\n",
       "   'ClusteringCoefficient': 0.351851851851851,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 309.2854010567901,\n",
       "   'BetweenessCentralityWeighted': 253.0}},\n",
       " '33': {'label': 'ROI_34',\n",
       "  'metadata': {'column_name': 'ROI_34',\n",
       "   'label_index': '34',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 3,\n",
       "   'Strength': 1.006846572905601,\n",
       "   'ClusteringCoefficient': 0.6666666666666661,\n",
       "   'Coreness': 3,\n",
       "   'BetweenessCentrality': 0.152027027027027,\n",
       "   'BetweenessCentralityWeighted': 0.0}},\n",
       " '34': {'label': 'ROI_35',\n",
       "  'metadata': {'column_name': 'ROI_35',\n",
       "   'label_index': '35',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 22,\n",
       "   'Strength': 7.455117696767168,\n",
       "   'ClusteringCoefficient': 0.48917748917748904,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 193.58275383751902,\n",
       "   'BetweenessCentralityWeighted': 283.0}},\n",
       " '35': {'label': 'ROI_36',\n",
       "  'metadata': {'column_name': 'ROI_36',\n",
       "   'label_index': '36',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 20,\n",
       "   'Strength': 6.917669388632682,\n",
       "   'ClusteringCoefficient': 0.44210526315789406,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 248.08775968786358,\n",
       "   'BetweenessCentralityWeighted': 226.0}},\n",
       " '36': {'label': 'ROI_37',\n",
       "  'metadata': {'column_name': 'ROI_37',\n",
       "   'label_index': '37',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 3,\n",
       "   'Strength': 0.9149083120136231,\n",
       "   'ClusteringCoefficient': 0.33333333333333304,\n",
       "   'Coreness': 3,\n",
       "   'BetweenessCentrality': 1.163588940225351,\n",
       "   'BetweenessCentralityWeighted': 3.0}},\n",
       " '37': {'label': 'ROI_38',\n",
       "  'metadata': {'column_name': 'ROI_38',\n",
       "   'label_index': '38',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 11,\n",
       "   'Strength': 3.493545784281527,\n",
       "   'ClusteringCoefficient': 0.6545454545454541,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 11.807852915754049,\n",
       "   'BetweenessCentralityWeighted': 19.0}},\n",
       " '38': {'label': 'ROI_39',\n",
       "  'metadata': {'column_name': 'ROI_39',\n",
       "   'label_index': '39',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 9,\n",
       "   'Strength': 3.081105526513824,\n",
       "   'ClusteringCoefficient': 0.555555555555555,\n",
       "   'Coreness': 7,\n",
       "   'BetweenessCentrality': 31.310861253920006,\n",
       "   'BetweenessCentralityWeighted': 45.0}},\n",
       " '39': {'label': 'ROI_40',\n",
       "  'metadata': {'column_name': 'ROI_40',\n",
       "   'label_index': '40',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 12,\n",
       "   'Strength': 3.849454845053048,\n",
       "   'ClusteringCoefficient': 0.409090909090909,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 94.51351656294138,\n",
       "   'BetweenessCentralityWeighted': 100.0}},\n",
       " '40': {'label': 'ROI_41',\n",
       "  'metadata': {'column_name': 'ROI_41',\n",
       "   'label_index': '41',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 13,\n",
       "   'Strength': 4.504137666109957,\n",
       "   'ClusteringCoefficient': 0.35897435897435903,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 101.14399024242935,\n",
       "   'BetweenessCentralityWeighted': 67.0}},\n",
       " '41': {'label': 'ROI_42',\n",
       "  'metadata': {'column_name': 'ROI_42',\n",
       "   'label_index': '42',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 21,\n",
       "   'Strength': 9.356680876722118,\n",
       "   'ClusteringCoefficient': 0.514285714285714,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 83.44637558149118,\n",
       "   'BetweenessCentralityWeighted': 76.0}},\n",
       " '42': {'label': 'ROI_43',\n",
       "  'metadata': {'column_name': 'ROI_43',\n",
       "   'label_index': '43',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 21,\n",
       "   'Strength': 7.064658180008736,\n",
       "   'ClusteringCoefficient': 0.39047619047619003,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 134.49544290201925,\n",
       "   'BetweenessCentralityWeighted': 197.0}},\n",
       " '43': {'label': 'ROI_44',\n",
       "  'metadata': {'column_name': 'ROI_44',\n",
       "   'label_index': '44',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 24,\n",
       "   'Strength': 10.36849732929748,\n",
       "   'ClusteringCoefficient': 0.40579710144927505,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 263.82462901849925,\n",
       "   'BetweenessCentralityWeighted': 215.0}},\n",
       " '44': {'label': 'ROI_45',\n",
       "  'metadata': {'column_name': 'ROI_45',\n",
       "   'label_index': '45',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 9,\n",
       "   'Strength': 2.666432714346861,\n",
       "   'ClusteringCoefficient': 0.36111111111111105,\n",
       "   'Coreness': 7,\n",
       "   'BetweenessCentrality': 31.410481658517625,\n",
       "   'BetweenessCentralityWeighted': 75.0}},\n",
       " '45': {'label': 'ROI_46',\n",
       "  'metadata': {'column_name': 'ROI_46',\n",
       "   'label_index': '46',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 14,\n",
       "   'Strength': 5.112080895554709,\n",
       "   'ClusteringCoefficient': 0.40659340659340604,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 97.57152726316176,\n",
       "   'BetweenessCentralityWeighted': 112.0}},\n",
       " '46': {'label': 'ROI_47',\n",
       "  'metadata': {'column_name': 'ROI_47',\n",
       "   'label_index': '47',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 17,\n",
       "   'Strength': 5.437990692671433,\n",
       "   'ClusteringCoefficient': 0.41911764705882304,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 137.5231110460734,\n",
       "   'BetweenessCentralityWeighted': 261.0}},\n",
       " '47': {'label': 'ROI_48',\n",
       "  'metadata': {'column_name': 'ROI_48',\n",
       "   'label_index': '48',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 26,\n",
       "   'Strength': 11.08124168214546,\n",
       "   'ClusteringCoefficient': 0.40615384615384603,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 268.9380331635536,\n",
       "   'BetweenessCentralityWeighted': 138.0}},\n",
       " '48': {'label': 'ROI_49',\n",
       "  'metadata': {'column_name': 'ROI_49',\n",
       "   'label_index': '49',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 27,\n",
       "   'Strength': 11.722931246632722,\n",
       "   'ClusteringCoefficient': 0.43874643874643804,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 189.34968102808244,\n",
       "   'BetweenessCentralityWeighted': 180.0}},\n",
       " '49': {'label': 'ROI_50',\n",
       "  'metadata': {'column_name': 'ROI_50',\n",
       "   'label_index': '50',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 17,\n",
       "   'Strength': 7.042080351886058,\n",
       "   'ClusteringCoefficient': 0.47794117647058804,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 61.47628066643113,\n",
       "   'BetweenessCentralityWeighted': 72.0}},\n",
       " '50': {'label': 'ROI_51',\n",
       "  'metadata': {'column_name': 'ROI_51',\n",
       "   'label_index': '51',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 24,\n",
       "   'Strength': 10.09593350090731,\n",
       "   'ClusteringCoefficient': 0.380434782608695,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 260.420221502042,\n",
       "   'BetweenessCentralityWeighted': 154.0}},\n",
       " '51': {'label': 'ROI_52',\n",
       "  'metadata': {'column_name': 'ROI_52',\n",
       "   'label_index': '52',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 22,\n",
       "   'Strength': 9.457030252357155,\n",
       "   'ClusteringCoefficient': 0.5108225108225101,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 71.84523517762578,\n",
       "   'BetweenessCentralityWeighted': 8.0}},\n",
       " '52': {'label': 'ROI_53',\n",
       "  'metadata': {'column_name': 'ROI_53',\n",
       "   'label_index': '53',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 9,\n",
       "   'Strength': 2.7534393346401282,\n",
       "   'ClusteringCoefficient': 0.36111111111111105,\n",
       "   'Coreness': 7,\n",
       "   'BetweenessCentrality': 66.24891672917734,\n",
       "   'BetweenessCentralityWeighted': 105.0}},\n",
       " '53': {'label': 'ROI_54',\n",
       "  'metadata': {'column_name': 'ROI_54',\n",
       "   'label_index': '54',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 13,\n",
       "   'Strength': 4.957458928402116,\n",
       "   'ClusteringCoefficient': 0.6538461538461531,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 26.801286542999684,\n",
       "   'BetweenessCentralityWeighted': 7.0}},\n",
       " '54': {'label': 'ROI_55',\n",
       "  'metadata': {'column_name': 'ROI_55',\n",
       "   'label_index': '55',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 11,\n",
       "   'Strength': 3.695383341332342,\n",
       "   'ClusteringCoefficient': 0.6727272727272721,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 17.86672300328344,\n",
       "   'BetweenessCentralityWeighted': 67.0}},\n",
       " '55': {'label': 'ROI_56',\n",
       "  'metadata': {'column_name': 'ROI_56',\n",
       "   'label_index': '56',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 13,\n",
       "   'Strength': 5.305916568191732,\n",
       "   'ClusteringCoefficient': 0.538461538461538,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 75.2727532678581,\n",
       "   'BetweenessCentralityWeighted': 67.0}},\n",
       " '56': {'label': 'ROI_57',\n",
       "  'metadata': {'column_name': 'ROI_57',\n",
       "   'label_index': '57',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 16,\n",
       "   'Strength': 5.841441481643545,\n",
       "   'ClusteringCoefficient': 0.46666666666666606,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 110.55265751312517,\n",
       "   'BetweenessCentralityWeighted': 139.0}},\n",
       " '57': {'label': 'ROI_58',\n",
       "  'metadata': {'column_name': 'ROI_58',\n",
       "   'label_index': '58',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 19,\n",
       "   'Strength': 7.585149018478408,\n",
       "   'ClusteringCoefficient': 0.46198830409356706,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 85.25804614259192,\n",
       "   'BetweenessCentralityWeighted': 91.0}},\n",
       " '58': {'label': 'ROI_59',\n",
       "  'metadata': {'column_name': 'ROI_59',\n",
       "   'label_index': '59',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 4,\n",
       "   'Strength': 1.3764748010068741,\n",
       "   'ClusteringCoefficient': 0.33333333333333304,\n",
       "   'Coreness': 4,\n",
       "   'BetweenessCentrality': 34.102311910064586,\n",
       "   'BetweenessCentralityWeighted': 25.0}},\n",
       " '59': {'label': 'ROI_60',\n",
       "  'metadata': {'column_name': 'ROI_60',\n",
       "   'label_index': '60',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 7.204009174829087,\n",
       "   'ClusteringCoefficient': 0.685714285714285,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 11.067853527459517,\n",
       "   'BetweenessCentralityWeighted': 8.0}},\n",
       " '60': {'label': 'ROI_61',\n",
       "  'metadata': {'column_name': 'ROI_61',\n",
       "   'label_index': '61',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 14,\n",
       "   'Strength': 7.378807615614471,\n",
       "   'ClusteringCoefficient': 0.6923076923076921,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 12.398113618231214,\n",
       "   'BetweenessCentralityWeighted': 1.0}},\n",
       " '61': {'label': 'ROI_62',\n",
       "  'metadata': {'column_name': 'ROI_62',\n",
       "   'label_index': '62',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 14,\n",
       "   'Strength': 6.740464828220804,\n",
       "   'ClusteringCoefficient': 0.604395604395604,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 26.62672492918132,\n",
       "   'BetweenessCentralityWeighted': 17.0}},\n",
       " '62': {'label': 'ROI_63',\n",
       "  'metadata': {'column_name': 'ROI_63',\n",
       "   'label_index': '63',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 10,\n",
       "   'Strength': 4.68803457680811,\n",
       "   'ClusteringCoefficient': 0.7555555555555551,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 6.350194182294998,\n",
       "   'BetweenessCentralityWeighted': 7.0}},\n",
       " '63': {'label': 'ROI_64',\n",
       "  'metadata': {'column_name': 'ROI_64',\n",
       "   'label_index': '64',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 6.46193919315354,\n",
       "   'ClusteringCoefficient': 0.47619047619047605,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 106.33512415468283,\n",
       "   'BetweenessCentralityWeighted': 48.0}},\n",
       " '64': {'label': 'ROI_65',\n",
       "  'metadata': {'column_name': 'ROI_65',\n",
       "   'label_index': '65',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 19,\n",
       "   'Strength': 6.945176780828994,\n",
       "   'ClusteringCoefficient': 0.43274853801169505,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 171.32218961909956,\n",
       "   'BetweenessCentralityWeighted': 242.0}},\n",
       " '65': {'label': 'ROI_66',\n",
       "  'metadata': {'column_name': 'ROI_66',\n",
       "   'label_index': '66',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 20,\n",
       "   'Strength': 7.654963629962418,\n",
       "   'ClusteringCoefficient': 0.631578947368421,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 24.112374782786205,\n",
       "   'BetweenessCentralityWeighted': 35.0}},\n",
       " '66': {'label': 'ROI_67',\n",
       "  'metadata': {'column_name': 'ROI_67',\n",
       "   'label_index': '67',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 23,\n",
       "   'Strength': 9.03154651359052,\n",
       "   'ClusteringCoefficient': 0.592885375494071,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 62.97950575384849,\n",
       "   'BetweenessCentralityWeighted': 51.0}},\n",
       " '67': {'label': 'ROI_68',\n",
       "  'metadata': {'column_name': 'ROI_68',\n",
       "   'label_index': '68',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 4.419572753217437,\n",
       "   'ClusteringCoefficient': 0.533333333333333,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 32.15547733635196,\n",
       "   'BetweenessCentralityWeighted': 72.0}},\n",
       " '68': {'label': 'ROI_69',\n",
       "  'metadata': {'column_name': 'ROI_69',\n",
       "   'label_index': '69',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 21,\n",
       "   'Strength': 7.974379198093641,\n",
       "   'ClusteringCoefficient': 0.533333333333333,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 165.18578893192287,\n",
       "   'BetweenessCentralityWeighted': 133.0}},\n",
       " '69': {'label': 'ROI_70',\n",
       "  'metadata': {'column_name': 'ROI_70',\n",
       "   'label_index': '70',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 16,\n",
       "   'Strength': 7.413019356003586,\n",
       "   'ClusteringCoefficient': 0.5750000000000001,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 54.94271060718275,\n",
       "   'BetweenessCentralityWeighted': 55.0}},\n",
       " '70': {'label': 'ROI_71',\n",
       "  'metadata': {'column_name': 'ROI_71',\n",
       "   'label_index': '71',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 29,\n",
       "   'Strength': 10.974553457146815,\n",
       "   'ClusteringCoefficient': 0.369458128078817,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 282.1002388381189,\n",
       "   'BetweenessCentralityWeighted': 273.0}},\n",
       " '71': {'label': 'ROI_72',\n",
       "  'metadata': {'column_name': 'ROI_72',\n",
       "   'label_index': '72',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 17,\n",
       "   'Strength': 6.657795091964857,\n",
       "   'ClusteringCoefficient': 0.34558823529411703,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 240.32106788730297,\n",
       "   'BetweenessCentralityWeighted': 213.0}},\n",
       " '72': {'label': 'ROI_73',\n",
       "  'metadata': {'column_name': 'ROI_73',\n",
       "   'label_index': '73',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 9,\n",
       "   'Strength': 2.521270714349587,\n",
       "   'ClusteringCoefficient': 0.47222222222222204,\n",
       "   'Coreness': 8,\n",
       "   'BetweenessCentrality': 50.37512816966573,\n",
       "   'BetweenessCentralityWeighted': 109.0}},\n",
       " '73': {'label': 'ROI_74',\n",
       "  'metadata': {'column_name': 'ROI_74',\n",
       "   'label_index': '74',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 28,\n",
       "   'Strength': 11.430412192262104,\n",
       "   'ClusteringCoefficient': 0.42592592592592504,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 194.35233073773492,\n",
       "   'BetweenessCentralityWeighted': 151.0}},\n",
       " '74': {'label': 'ROI_75',\n",
       "  'metadata': {'column_name': 'ROI_75',\n",
       "   'label_index': '75',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 16,\n",
       "   'Strength': 4.8560455985247195,\n",
       "   'ClusteringCoefficient': 0.44166666666666604,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 96.5850232614141,\n",
       "   'BetweenessCentralityWeighted': 241.0}},\n",
       " '75': {'label': 'ROI_76',\n",
       "  'metadata': {'column_name': 'ROI_76',\n",
       "   'label_index': '76',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 18,\n",
       "   'Strength': 6.39555422138543,\n",
       "   'ClusteringCoefficient': 0.28758169934640504,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 235.39312936835685,\n",
       "   'BetweenessCentralityWeighted': 184.0}},\n",
       " '76': {'label': 'ROI_77',\n",
       "  'metadata': {'column_name': 'ROI_77',\n",
       "   'label_index': '77',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 30,\n",
       "   'Strength': 11.679179165360557,\n",
       "   'ClusteringCoefficient': 0.40919540229885004,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 215.76075410344976,\n",
       "   'BetweenessCentralityWeighted': 167.0}},\n",
       " '77': {'label': 'ROI_78',\n",
       "  'metadata': {'column_name': 'ROI_78',\n",
       "   'label_index': '78',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 14,\n",
       "   'Strength': 4.679947322608625,\n",
       "   'ClusteringCoefficient': 0.40659340659340604,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 125.28076246394666,\n",
       "   'BetweenessCentralityWeighted': 127.0}},\n",
       " '78': {'label': 'ROI_79',\n",
       "  'metadata': {'column_name': 'ROI_79',\n",
       "   'label_index': '79',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 36,\n",
       "   'Strength': 15.09848697068168,\n",
       "   'ClusteringCoefficient': 0.457142857142857,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 220.45332369122488,\n",
       "   'BetweenessCentralityWeighted': 94.0}},\n",
       " '79': {'label': 'ROI_80',\n",
       "  'metadata': {'column_name': 'ROI_80',\n",
       "   'label_index': '80',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 26,\n",
       "   'Strength': 9.080203742494806,\n",
       "   'ClusteringCoefficient': 0.538461538461538,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 83.84449003496742,\n",
       "   'BetweenessCentralityWeighted': 87.0}},\n",
       " '80': {'label': 'ROI_81',\n",
       "  'metadata': {'column_name': 'ROI_81',\n",
       "   'label_index': '81',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 13,\n",
       "   'Strength': 4.368242125698657,\n",
       "   'ClusteringCoefficient': 0.461538461538461,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 78.91104034886985,\n",
       "   'BetweenessCentralityWeighted': 73.0}},\n",
       " '81': {'label': 'ROI_82',\n",
       "  'metadata': {'column_name': 'ROI_82',\n",
       "   'label_index': '82',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 29,\n",
       "   'Strength': 11.839485932682821,\n",
       "   'ClusteringCoefficient': 0.529556650246305,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 132.91278313776823,\n",
       "   'BetweenessCentralityWeighted': 70.0}},\n",
       " '82': {'label': 'ROI_83',\n",
       "  'metadata': {'column_name': 'ROI_83',\n",
       "   'label_index': '83',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 7,\n",
       "   'Strength': 2.522981878184617,\n",
       "   'ClusteringCoefficient': 0.42857142857142805,\n",
       "   'Coreness': 7,\n",
       "   'BetweenessCentrality': 51.32045398883333,\n",
       "   'BetweenessCentralityWeighted': 50.0}},\n",
       " '83': {'label': 'ROI_84',\n",
       "  'metadata': {'column_name': 'ROI_84',\n",
       "   'label_index': '84',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 23,\n",
       "   'Strength': 8.460276545665732,\n",
       "   'ClusteringCoefficient': 0.577075098814229,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 72.55910216715515,\n",
       "   'BetweenessCentralityWeighted': 107.0}},\n",
       " '84': {'label': 'ROI_85',\n",
       "  'metadata': {'column_name': 'ROI_85',\n",
       "   'label_index': '85',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 16,\n",
       "   'Strength': 6.044956278005842,\n",
       "   'ClusteringCoefficient': 0.6083333333333331,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 21.973157059553774,\n",
       "   'BetweenessCentralityWeighted': 24.0}},\n",
       " '85': {'label': 'ROI_86',\n",
       "  'metadata': {'column_name': 'ROI_86',\n",
       "   'label_index': '86',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 13,\n",
       "   'Strength': 4.161142886295006,\n",
       "   'ClusteringCoefficient': 0.7179487179487181,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 7.507125655995951,\n",
       "   'BetweenessCentralityWeighted': 20.0}},\n",
       " '86': {'label': 'ROI_87',\n",
       "  'metadata': {'column_name': 'ROI_87',\n",
       "   'label_index': '87',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 20,\n",
       "   'Strength': 6.8164145662824165,\n",
       "   'ClusteringCoefficient': 0.557894736842105,\n",
       "   'Coreness': 12,\n",
       "   'BetweenessCentrality': 35.94813504589913,\n",
       "   'BetweenessCentralityWeighted': 34.0}},\n",
       " '87': {'label': 'ROI_88',\n",
       "  'metadata': {'column_name': 'ROI_88',\n",
       "   'label_index': '88',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 16,\n",
       "   'Strength': 5.579996739902787,\n",
       "   'ClusteringCoefficient': 0.5,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 24.95073163745086,\n",
       "   'BetweenessCentralityWeighted': 25.0}},\n",
       " '88': {'label': 'ROI_89',\n",
       "  'metadata': {'column_name': 'ROI_89',\n",
       "   'label_index': '89',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 9,\n",
       "   'Strength': 2.925345359474783,\n",
       "   'ClusteringCoefficient': 0.805555555555555,\n",
       "   'Coreness': 9,\n",
       "   'BetweenessCentrality': 2.780715589962071,\n",
       "   'BetweenessCentralityWeighted': 19.0}},\n",
       " '89': {'label': 'ROI_90',\n",
       "  'metadata': {'column_name': 'ROI_90',\n",
       "   'label_index': '90',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 9,\n",
       "   'Strength': 2.709396375235252,\n",
       "   'ClusteringCoefficient': 0.33333333333333304,\n",
       "   'Coreness': 9,\n",
       "   'BetweenessCentrality': 123.6402244884266,\n",
       "   'BetweenessCentralityWeighted': 203.0}},\n",
       " '90': {'label': 'ROI_91',\n",
       "  'metadata': {'column_name': 'ROI_91',\n",
       "   'label_index': '91',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 16,\n",
       "   'Strength': 6.783631172094677,\n",
       "   'ClusteringCoefficient': 0.6000000000000001,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 76.02026546796779,\n",
       "   'BetweenessCentralityWeighted': 99.0}},\n",
       " '91': {'label': 'ROI_92',\n",
       "  'metadata': {'column_name': 'ROI_92',\n",
       "   'label_index': '92',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 17,\n",
       "   'Strength': 5.901584845355378,\n",
       "   'ClusteringCoefficient': 0.35294117647058804,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 124.74560931174643,\n",
       "   'BetweenessCentralityWeighted': 177.0}},\n",
       " '92': {'label': 'ROI_93',\n",
       "  'metadata': {'column_name': 'ROI_93',\n",
       "   'label_index': '93',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 8,\n",
       "   'Strength': 3.495433969862089,\n",
       "   'ClusteringCoefficient': 0.7142857142857141,\n",
       "   'Coreness': 8,\n",
       "   'BetweenessCentrality': 7.163112818259099,\n",
       "   'BetweenessCentralityWeighted': 0.0}},\n",
       " '93': {'label': 'ROI_94',\n",
       "  'metadata': {'column_name': 'ROI_94',\n",
       "   'label_index': '94',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 3,\n",
       "   'Strength': 0.8093926931050851,\n",
       "   'ClusteringCoefficient': 0.6666666666666661,\n",
       "   'Coreness': 3,\n",
       "   'BetweenessCentrality': 1.077518315018315,\n",
       "   'BetweenessCentralityWeighted': 11.0}},\n",
       " '94': {'label': 'ROI_95',\n",
       "  'metadata': {'column_name': 'ROI_95',\n",
       "   'label_index': '95',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 13,\n",
       "   'Strength': 4.6008379097522845,\n",
       "   'ClusteringCoefficient': 0.47435897435897406,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 55.26753280336404,\n",
       "   'BetweenessCentralityWeighted': 68.0}},\n",
       " '95': {'label': 'ROI_96',\n",
       "  'metadata': {'column_name': 'ROI_96',\n",
       "   'label_index': '96',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 1,\n",
       "   'Strength': 0.27160235822752904,\n",
       "   'ClusteringCoefficient': 0.0,\n",
       "   'Coreness': 1,\n",
       "   'BetweenessCentrality': 0.0,\n",
       "   'BetweenessCentralityWeighted': 0.0}},\n",
       " '96': {'label': 'ROI_97',\n",
       "  'metadata': {'column_name': 'ROI_97',\n",
       "   'label_index': '97',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 11,\n",
       "   'Strength': 3.400752641258918,\n",
       "   'ClusteringCoefficient': 0.636363636363636,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 18.012268078000837,\n",
       "   'BetweenessCentralityWeighted': 65.0}},\n",
       " '97': {'label': 'ROI_98',\n",
       "  'metadata': {'column_name': 'ROI_98',\n",
       "   'label_index': '98',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 12,\n",
       "   'Strength': 4.580334635782658,\n",
       "   'ClusteringCoefficient': 0.33333333333333304,\n",
       "   'Coreness': 8,\n",
       "   'BetweenessCentrality': 144.0562330932391,\n",
       "   'BetweenessCentralityWeighted': 77.0}},\n",
       " '98': {'label': 'ROI_99',\n",
       "  'metadata': {'column_name': 'ROI_99',\n",
       "   'label_index': '99',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 7,\n",
       "   'Strength': 2.4303301050202553,\n",
       "   'ClusteringCoefficient': 0.47619047619047605,\n",
       "   'Coreness': 7,\n",
       "   'BetweenessCentrality': 36.44414859887704,\n",
       "   'BetweenessCentralityWeighted': 24.0}},\n",
       " '99': {'label': 'ROI_100',\n",
       "  'metadata': {'column_name': 'ROI_100',\n",
       "   'label_index': '100',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 16,\n",
       "   'Strength': 7.158369725762918,\n",
       "   'ClusteringCoefficient': 0.558333333333333,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 66.85057642852374,\n",
       "   'BetweenessCentralityWeighted': 57.0}},\n",
       " '100': {'label': 'ROI_101',\n",
       "  'metadata': {'column_name': 'ROI_101',\n",
       "   'label_index': '101',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 22,\n",
       "   'Strength': 7.5209399569629625,\n",
       "   'ClusteringCoefficient': 0.329004329004329,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 246.43124552277152,\n",
       "   'BetweenessCentralityWeighted': 179.0}},\n",
       " '101': {'label': 'ROI_102',\n",
       "  'metadata': {'column_name': 'ROI_102',\n",
       "   'label_index': '102',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 24,\n",
       "   'Strength': 9.834997951049669,\n",
       "   'ClusteringCoefficient': 0.409420289855072,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 194.3583473362888,\n",
       "   'BetweenessCentralityWeighted': 201.0}},\n",
       " '102': {'label': 'ROI_103',\n",
       "  'metadata': {'column_name': 'ROI_103',\n",
       "   'label_index': '103',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 6,\n",
       "   'Strength': 2.394420706635939,\n",
       "   'ClusteringCoefficient': 0.533333333333333,\n",
       "   'Coreness': 6,\n",
       "   'BetweenessCentrality': 9.38480174424801,\n",
       "   'BetweenessCentralityWeighted': 4.0}},\n",
       " '103': {'label': 'ROI_104',\n",
       "  'metadata': {'column_name': 'ROI_104',\n",
       "   'label_index': '104',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 11,\n",
       "   'Strength': 4.205208088476397,\n",
       "   'ClusteringCoefficient': 0.6545454545454541,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 15.120855261420939,\n",
       "   'BetweenessCentralityWeighted': 18.0}},\n",
       " '104': {'label': 'ROI_105',\n",
       "  'metadata': {'column_name': 'ROI_105',\n",
       "   'label_index': '105',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 5.669800393894649,\n",
       "   'ClusteringCoefficient': 0.457142857142857,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 85.37076558280211,\n",
       "   'BetweenessCentralityWeighted': 106.0}},\n",
       " '105': {'label': 'ROI_106',\n",
       "  'metadata': {'column_name': 'ROI_106',\n",
       "   'label_index': '106',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 11,\n",
       "   'Strength': 3.418741362939656,\n",
       "   'ClusteringCoefficient': 0.5454545454545451,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 27.509121253416243,\n",
       "   'BetweenessCentralityWeighted': 77.0}},\n",
       " '106': {'label': 'ROI_107',\n",
       "  'metadata': {'column_name': 'ROI_107',\n",
       "   'label_index': '107',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 22,\n",
       "   'Strength': 10.16776109563061,\n",
       "   'ClusteringCoefficient': 0.47619047619047605,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 129.70136088318645,\n",
       "   'BetweenessCentralityWeighted': 11.0}},\n",
       " '107': {'label': 'ROI_108',\n",
       "  'metadata': {'column_name': 'ROI_108',\n",
       "   'label_index': '108',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 23,\n",
       "   'Strength': 10.753887939259858,\n",
       "   'ClusteringCoefficient': 0.50197628458498,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 87.99451684631143,\n",
       "   'BetweenessCentralityWeighted': 24.0}},\n",
       " '108': {'label': 'ROI_109',\n",
       "  'metadata': {'column_name': 'ROI_109',\n",
       "   'label_index': '109',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 13,\n",
       "   'Strength': 5.83555442902426,\n",
       "   'ClusteringCoefficient': 0.6153846153846151,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 29.09348239227093,\n",
       "   'BetweenessCentralityWeighted': 31.0}},\n",
       " '109': {'label': 'ROI_110',\n",
       "  'metadata': {'column_name': 'ROI_110',\n",
       "   'label_index': '110',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 12,\n",
       "   'Strength': 4.55270630715941,\n",
       "   'ClusteringCoefficient': 0.621212121212121,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 22.89296178410181,\n",
       "   'BetweenessCentralityWeighted': 30.0}},\n",
       " '110': {'label': 'ROI_111',\n",
       "  'metadata': {'column_name': 'ROI_111',\n",
       "   'label_index': '111',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 21,\n",
       "   'Strength': 7.4804785972394034,\n",
       "   'ClusteringCoefficient': 0.514285714285714,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 124.66222610354822,\n",
       "   'BetweenessCentralityWeighted': 131.0}},\n",
       " '111': {'label': 'ROI_112',\n",
       "  'metadata': {'column_name': 'ROI_112',\n",
       "   'label_index': '112',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 14,\n",
       "   'Strength': 5.283728220528501,\n",
       "   'ClusteringCoefficient': 0.494505494505494,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 67.24135524204007,\n",
       "   'BetweenessCentralityWeighted': 91.0}},\n",
       " '112': {'label': 'ROI_113',\n",
       "  'metadata': {'column_name': 'ROI_113',\n",
       "   'label_index': '113',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 16,\n",
       "   'Strength': 6.366512894009159,\n",
       "   'ClusteringCoefficient': 0.48333333333333306,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 95.17916630918448,\n",
       "   'BetweenessCentralityWeighted': 37.0}},\n",
       " '113': {'label': 'ROI_114',\n",
       "  'metadata': {'column_name': 'ROI_114',\n",
       "   'label_index': '114',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 12,\n",
       "   'Strength': 4.577575722590941,\n",
       "   'ClusteringCoefficient': 0.651515151515151,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 52.812381169666,\n",
       "   'BetweenessCentralityWeighted': 64.0}},\n",
       " '114': {'label': 'ROI_115',\n",
       "  'metadata': {'column_name': 'ROI_115',\n",
       "   'label_index': '115',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 3,\n",
       "   'Strength': 0.809917147843994,\n",
       "   'ClusteringCoefficient': 0.33333333333333304,\n",
       "   'Coreness': 3,\n",
       "   'BetweenessCentrality': 1.142320904790846,\n",
       "   'BetweenessCentralityWeighted': 9.0}},\n",
       " '115': {'label': 'ROI_116',\n",
       "  'metadata': {'column_name': 'ROI_116',\n",
       "   'label_index': '116',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 17,\n",
       "   'Strength': 6.293138559287134,\n",
       "   'ClusteringCoefficient': 0.36029411764705804,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 185.1989024974625,\n",
       "   'BetweenessCentralityWeighted': 101.0}},\n",
       " '116': {'label': 'ROI_117',\n",
       "  'metadata': {'column_name': 'ROI_117',\n",
       "   'label_index': '117',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 20,\n",
       "   'Strength': 6.483702744591169,\n",
       "   'ClusteringCoefficient': 0.421052631578947,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 103.01169489255989,\n",
       "   'BetweenessCentralityWeighted': 162.0}},\n",
       " '117': {'label': 'ROI_118',\n",
       "  'metadata': {'column_name': 'ROI_118',\n",
       "   'label_index': '118',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 14,\n",
       "   'Strength': 5.020619334896064,\n",
       "   'ClusteringCoefficient': 0.42857142857142805,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 65.80156593334273,\n",
       "   'BetweenessCentralityWeighted': 36.0}},\n",
       " '118': {'label': 'ROI_119',\n",
       "  'metadata': {'column_name': 'ROI_119',\n",
       "   'label_index': '119',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 25,\n",
       "   'Strength': 8.510621177580633,\n",
       "   'ClusteringCoefficient': 0.43,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 111.10160935742684,\n",
       "   'BetweenessCentralityWeighted': 124.0}},\n",
       " '119': {'label': 'ROI_120',\n",
       "  'metadata': {'column_name': 'ROI_120',\n",
       "   'label_index': '120',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 10,\n",
       "   'Strength': 3.237404167222831,\n",
       "   'ClusteringCoefficient': 0.37777777777777705,\n",
       "   'Coreness': 9,\n",
       "   'BetweenessCentrality': 27.924231440655486,\n",
       "   'BetweenessCentralityWeighted': 49.0}},\n",
       " '120': {'label': 'ROI_121',\n",
       "  'metadata': {'column_name': 'ROI_121',\n",
       "   'label_index': '121',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 5.166097777407769,\n",
       "   'ClusteringCoefficient': 0.38095238095238004,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 168.75028669662413,\n",
       "   'BetweenessCentralityWeighted': 204.0}},\n",
       " '121': {'label': 'ROI_122',\n",
       "  'metadata': {'column_name': 'ROI_122',\n",
       "   'label_index': '122',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 8,\n",
       "   'Strength': 2.594058858404728,\n",
       "   'ClusteringCoefficient': 0.392857142857142,\n",
       "   'Coreness': 7,\n",
       "   'BetweenessCentrality': 48.46137623874201,\n",
       "   'BetweenessCentralityWeighted': 97.0}},\n",
       " '122': {'label': 'ROI_123',\n",
       "  'metadata': {'column_name': 'ROI_123',\n",
       "   'label_index': '123',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 4.47899577414493,\n",
       "   'ClusteringCoefficient': 0.561904761904761,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 88.69148634460227,\n",
       "   'BetweenessCentralityWeighted': 179.0}},\n",
       " '123': {'label': 'ROI_124',\n",
       "  'metadata': {'column_name': 'ROI_124',\n",
       "   'label_index': '124',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 20,\n",
       "   'Strength': 7.184042208978452,\n",
       "   'ClusteringCoefficient': 0.294736842105263,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 222.99269447649854,\n",
       "   'BetweenessCentralityWeighted': 200.0}},\n",
       " '124': {'label': 'ROI_125',\n",
       "  'metadata': {'column_name': 'ROI_125',\n",
       "   'label_index': '125',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 20,\n",
       "   'Strength': 7.11953351109878,\n",
       "   'ClusteringCoefficient': 0.45263157894736805,\n",
       "   'Coreness': 11,\n",
       "   'BetweenessCentrality': 87.2818831974086,\n",
       "   'BetweenessCentralityWeighted': 101.0}},\n",
       " '125': {'label': 'ROI_126',\n",
       "  'metadata': {'column_name': 'ROI_126',\n",
       "   'label_index': '126',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 15,\n",
       "   'Strength': 5.2815677557373455,\n",
       "   'ClusteringCoefficient': 0.514285714285714,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 30.554024568654505,\n",
       "   'BetweenessCentralityWeighted': 59.0}},\n",
       " '126': {'label': 'ROI_127',\n",
       "  'metadata': {'column_name': 'ROI_127',\n",
       "   'label_index': '127',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 7,\n",
       "   'Strength': 2.399112812420962,\n",
       "   'ClusteringCoefficient': 0.38095238095238004,\n",
       "   'Coreness': 6,\n",
       "   'BetweenessCentrality': 36.92617979092759,\n",
       "   'BetweenessCentralityWeighted': 37.0}},\n",
       " '127': {'label': 'ROI_128',\n",
       "  'metadata': {'column_name': 'ROI_128',\n",
       "   'label_index': '128',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 11,\n",
       "   'Strength': 3.286025399057276,\n",
       "   'ClusteringCoefficient': 0.18181818181818102,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 176.87525476785154,\n",
       "   'BetweenessCentralityWeighted': 267.0}},\n",
       " '128': {'label': 'ROI_129',\n",
       "  'metadata': {'column_name': 'ROI_129',\n",
       "   'label_index': '129',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 18,\n",
       "   'Strength': 6.36813808532047,\n",
       "   'ClusteringCoefficient': 0.43790849673202603,\n",
       "   'Coreness': 10,\n",
       "   'BetweenessCentrality': 145.39771491438506,\n",
       "   'BetweenessCentralityWeighted': 125.0}},\n",
       " '129': {'label': 'ROI_130',\n",
       "  'metadata': {'column_name': 'ROI_130',\n",
       "   'label_index': '130',\n",
       "   'in_parc': 1,\n",
       "   'Degree': 11,\n",
       "   'Strength': 3.96525879249246,\n",
       "   'ClusteringCoefficient': 0.636363636363636,\n",
       "   'Coreness': 9,\n",
       "   'BetweenessCentrality': 24.683636445815996,\n",
       "   'BetweenessCentralityWeighted': 17.0}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_yeo_test['nodes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     16.738462\n",
       "1     17.030769\n",
       "2     17.415385\n",
       "3     12.523077\n",
       "4     10.846154\n",
       "5     11.600000\n",
       "6     14.723077\n",
       "7     19.030769\n",
       "8     11.215385\n",
       "9     12.907692\n",
       "10    18.092308\n",
       "11    16.076923\n",
       "12    13.107692\n",
       "13    19.984615\n",
       "14    16.600000\n",
       "15    18.815385\n",
       "16    15.753846\n",
       "17    12.030769\n",
       "18    16.753846\n",
       "19     9.123077\n",
       "20    15.030769\n",
       "21    10.107692\n",
       "22    23.492308\n",
       "23    20.138462\n",
       "24    16.553846\n",
       "25    15.292308\n",
       "26    12.461538\n",
       "27    19.753846\n",
       "28    12.753846\n",
       "29     8.830769\n",
       "30    14.400000\n",
       "31    14.907692\n",
       "Name: average_degree, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_yeo_network.loc[fmri_yeo_network['classID'] == 'hcp-retest']['average_degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rpy2 in /opt/conda/lib/python3.7/site-packages (3.1.0)\n",
      "Requirement already satisfied: tzlocal in /opt/conda/lib/python3.7/site-packages (from rpy2) (2.0.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from rpy2) (2020.1)\n",
      "Collecting pytest\n",
      "  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: simplegeneric in /opt/conda/lib/python3.7/site-packages (from rpy2) (0.8.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from rpy2) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from rpy2) (2.11.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest->rpy2) (19.3.0)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.10.0-py2.py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 2.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pluggy<1.0.0a1,>=0.12\n",
      "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from pytest->rpy2) (1.6.0)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest->rpy2) (20.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->rpy2) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->rpy2) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->rpy2) (3.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->pytest->rpy2) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytest->rpy2) (2.4.7)\n",
      "Installing collected packages: toml, py, pluggy, iniconfig, pytest\n",
      "Successfully installed iniconfig-1.1.1 pluggy-0.13.1 py-1.10.0 pytest-6.2.4 toml-0.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import DataFrame, FloatVector, IntVector\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in loadNamespace(name) : there is no package called ‘psych’\n",
      "Calls: <Anonymous> ... loadNamespace -> withRestarts -> withOneRestart -> doWithOneRestart\n",
      "\n"
     ]
    },
    {
     "ename": "RRuntimeError",
     "evalue": "Error in loadNamespace(name) : there is no package called ‘psych’\nCalls: <Anonymous> ... loadNamespace -> withRestarts -> withOneRestart -> doWithOneRestart\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-5acd0d067f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr_icc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"psych\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/rpy2/robjects/packages.py\u001b[0m in \u001b[0;36mimportr\u001b[0;34m(name, lib_loc, robject_translations, signature_translation, suppress_messages, on_conflict, symbol_r2python, symbol_resolve, data)\u001b[0m\n\u001b[1;32m    475\u001b[0m     if _package_has_namespace(rname,\n\u001b[1;32m    476\u001b[0m                               _system_file(package=rname)):\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_namespace_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mexported_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_namespace_exports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_res_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cdata_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                     error_occured))\n\u001b[1;32m    784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_occured\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_geterrmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in loadNamespace(name) : there is no package called ‘psych’\nCalls: <Anonymous> ... loadNamespace -> withRestarts -> withOneRestart -> doWithOneRestart\n"
     ]
    }
   ],
   "source": [
    "r_icc = importr(\"psych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r_icc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-22047772c9a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr_icc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICCbare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'classID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'average_degree'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmri_yeo_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'r_icc' is not defined"
     ]
    }
   ],
   "source": [
    "r_icc.ICCbare('classID','average_degree',data=fmri_yeo_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import ones, kron, mean, eye, hstack, dot, tile\n",
    "from numpy.linalg import pinv\n",
    "\n",
    "def icc(Y, icc_type='ICC(2,1)'):\n",
    "    ''' Calculate intraclass correlation coefficient\n",
    "\n",
    "    ICC Formulas are based on:\n",
    "    Shrout, P. E., & Fleiss, J. L. (1979). Intraclass correlations: uses in\n",
    "    assessing rater reliability. Psychological bulletin, 86(2), 420.\n",
    "    icc1:  x_ij = mu + beta_j + w_ij\n",
    "    icc2/3:  x_ij = mu + alpha_i + beta_j + (ab)_ij + epsilon_ij\n",
    "    Code modifed from nipype algorithms.icc\n",
    "    https://github.com/nipy/nipype/blob/master/nipype/algorithms/icc.py\n",
    "\n",
    "    Args:\n",
    "        Y: The data Y are entered as a 'table' ie. subjects are in rows and repeated\n",
    "            measures in columns\n",
    "        icc_type: type of ICC to calculate. (ICC(2,1), ICC(2,k), ICC(3,1), ICC(3,k)) \n",
    "    Returns:\n",
    "        ICC: (np.array) intraclass correlation coefficient\n",
    "    '''\n",
    "\n",
    "    [n, k] = Y.shape\n",
    "\n",
    "    # Degrees of Freedom\n",
    "    dfc = k - 1\n",
    "    dfe = (n - 1) * (k-1)\n",
    "    dfr = n - 1\n",
    "\n",
    "    # Sum Square Total\n",
    "    mean_Y = np.mean(Y)\n",
    "    SST = ((Y - mean_Y) ** 2).sum()\n",
    "\n",
    "    # create the design matrix for the different levels\n",
    "    x = np.kron(np.eye(k), np.ones((n, 1)))  # sessions\n",
    "    x0 = np.tile(np.eye(n), (k, 1))  # subjects\n",
    "    X = np.hstack([x, x0])\n",
    "\n",
    "    # Sum Square Error\n",
    "    predicted_Y = np.dot(np.dot(np.dot(X, np.linalg.pinv(np.dot(X.T, X))),\n",
    "                                X.T), Y.flatten('F'))\n",
    "    residuals = Y.flatten('F') - predicted_Y\n",
    "    SSE = (residuals ** 2).sum()\n",
    "\n",
    "    MSE = SSE / dfe\n",
    "\n",
    "    # Sum square column effect - between colums\n",
    "    SSC = ((np.mean(Y, 0) - mean_Y) ** 2).sum() * n\n",
    "    MSC = SSC / dfc  # / n (without n in SPSS results)\n",
    "\n",
    "    # Sum Square subject effect - between rows/subjects\n",
    "    SSR = SST - SSC - SSE\n",
    "    MSR = SSR / dfr\n",
    "\n",
    "    if icc_type == 'icc1':\n",
    "        # ICC(2,1) = (mean square subject - mean square error) /\n",
    "        # (mean square subject + (k-1)*mean square error +\n",
    "        # k*(mean square columns - mean square error)/n)\n",
    "        # ICC = (MSR - MSRW) / (MSR + (k-1) * MSRW)\n",
    "        NotImplementedError(\"This method isn't implemented yet.\")\n",
    "\n",
    "    elif icc_type == 'ICC(2,1)' or icc_type == 'ICC(2,k)':\n",
    "        # ICC(2,1) = (mean square subject - mean square error) /\n",
    "        # (mean square subject + (k-1)*mean square error +\n",
    "        # k*(mean square columns - mean square error)/n)\n",
    "        if icc_type == 'ICC(2,k)':\n",
    "            k = 1\n",
    "        ICC = (MSR - MSE) / (MSR + (k-1) * MSE + k * (MSC - MSE) / n)\n",
    "\n",
    "    elif icc_type == 'ICC(3,1)' or icc_type == 'ICC(3,k)':\n",
    "        # ICC(3,1) = (mean square subject - mean square error) /\n",
    "        # (mean square subject + (k-1)*mean square error)\n",
    "        if icc_type == 'ICC(3,k)':\n",
    "            k = 1\n",
    "        ICC = (MSR - MSE) / (MSR + (k-1) * MSE)\n",
    "\n",
    "    return ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate([fmri_yeo_network.loc[fmri_yeo_network['classID'] == 'hcp-test']['average_degree'].values.tolist(),fmri_yeo_network.loc[fmri_yeo_network['classID'] == 'hcp-retest']['average_degree'].values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['degree_test'] = fmri_yeo_network.loc[fmri_yeo_network['classID'] == 'hcp-test']['average_degree'].values.tolist()\n",
    "test['degree_retest'] = fmri_yeo_network.loc[fmri_yeo_network['classID'] == 'hcp-retest']['average_degree'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7005055199846963"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc(Y, icc_type='ICC(2,1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
